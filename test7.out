Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(wandb_model_trainer.py:3251834): Gdk-CRITICAL **: 11:34:07.714: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
wandb: Agent Starting Run: mhu4437d with config:
wandb: 	batch_size: 5
wandb: 	criterion: cross_entropy
wandb: 	epochs: 100
wandb: 	learning_rate: 0.07112
wandb: 	model_name: cifar10_mobilenetv2_x1_4
wandb: 	momentum: 0.9
wandb: 	optimizer: nesterov
wandb: 	pretrained: False
wandb: 	scheduler: Cosine Annealing
wandb: 	transformation: models/pretrained/U_w_means_0-005174736492335796_n0-0014449692098423839_n0-0010137659264728427_and_stds_1-130435824394226_1-128873586654663_1-1922636032104492_.pt
wandb: 	use_SAM: True
wandb: 	weight_decay: 1e-05
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
Files already downloaded and verified
Files already downloaded and verified
CIFAR10 is Loaded
Create sweep with ID: wl5t0np4
Sweep URL: https://wandb.ai/naddeok/CIFAR10/sweeps/wl5t0np4
wandb: wandb version 0.10.31 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-05-31 11:34:11.794685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-31 11:34:11.796890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
wandb: Tracking run with wandb version 0.10.30
wandb: Syncing run noble-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/naddeok/CIFAR10
wandb: üßπ View sweep at https://wandb.ai/naddeok/CIFAR10/sweeps/wl5t0np4
wandb: üöÄ View run at https://wandb.ai/naddeok/CIFAR10/runs/mhu4437d
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210531_113410-mhu4437d
wandb: Run `wandb offline` to turn off syncing.

signal only works in main thread
Using cache found in /home/naddeok5/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master
Epoch:  1 	Train Loss:  0.18358960870528593 	Val Loss:  0.003935142004489899
Epoch:  3 	Train Loss:  0.16391113547876476 	Val Loss:  0.003606900465488434
Epoch:  5 	Train Loss:  0.15458240093072875 	Val Loss:  0.00391753495335579
Epoch:  7 	Train Loss:  0.14784635870873927 	Val Loss:  0.0035273059964179994
Epoch:  9 	Train Loss:  0.14213754386605695 	Val Loss:  0.0035873981416225434
Epoch:  11 	Train Loss:  0.13895758012594656 	Val Loss:  0.0036020564675331114
Epoch:  13 	Train Loss:  0.13468126755570992 	Val Loss:  0.0034023234128952025
Epoch:  15 	Train Loss:  0.1313545286798477 	Val Loss:  0.003583028620481491
Epoch:  17 	Train Loss:  0.13194302266371435 	Val Loss:  0.0035475360572338106
Epoch:  19 	Train Loss:  0.1274695551844407 	Val Loss:  0.0034242487907409666
Epoch:  21 	Train Loss:  0.12279525621111505 	Val Loss:  0.003588613176345825
Epoch:  23 	Train Loss:  0.12050330141762272 	Val Loss:  0.0035960869550704954
Epoch:  25 	Train Loss:  0.11828712391188369 	Val Loss:  0.00339913227558136
Epoch:  27 	Train Loss:  0.11445003042315599 	Val Loss:  0.003619139802455902
