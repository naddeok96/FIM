wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-09 22:27:02.973631: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-09 22:27:02.978419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run brisk-mountain-6
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/3hpgqvww
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220109_222700-3hpgqvww
wandb: Run `wandb offline` to turn off syncing.
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 0
Training on Rank 2
Training on Rank 1
Epoch:  1 	Train/Val Loss:  2089.88208 / 442.24756 	Train/Val Acc:  99.84 / 91.79
Epoch:  2 	Train/Val Loss:  2089.76855 / 442.25916 	Train/Val Acc:  99.85 / 91.95
Epoch:  3 	Train/Val Loss:  2089.80688 / 442.42532 	Train/Val Acc:  99.85 / 91.82
Epoch:  4 	Train/Val Loss:  2089.80103 / 442.26334 	Train/Val Acc:  99.87 / 92.0
Epoch:  5 	Train/Val Loss:  2089.62476 / 442.4902 	Train/Val Acc:  99.86 / 91.97
Epoch:  6 	Train/Val Loss:  2089.72168 / 442.62347 	Train/Val Acc:  99.86 / 91.87
Epoch:  7 	Train/Val Loss:  2089.65942 / 442.83118 	Train/Val Acc:  99.88 / 91.9
Epoch:  8 	Train/Val Loss:  2089.5686 / 443.03931 	Train/Val Acc:  99.87 / 91.92
Epoch:  9 	Train/Val Loss:  2089.69873 / 443.23465 	Train/Val Acc:  99.85 / 91.83
Epoch:  10 	Train/Val Loss:  2089.63916 / 443.41351 	Train/Val Acc:  99.84 / 91.85
Epoch:  11 	Train/Val Loss:  2089.5332 / 443.66336 	Train/Val Acc:  99.87 / 91.93
Epoch:  12 	Train/Val Loss:  2089.56177 / 444.03745 	Train/Val Acc:  99.85 / 91.82
Epoch:  13 	Train/Val Loss:  2089.52173 / 444.03571 	Train/Val Acc:  99.85 / 91.87
Epoch:  14 	Train/Val Loss:  2089.67603 / 444.18286 	Train/Val Acc:  99.82 / 91.94
Epoch:  15 	Train/Val Loss:  2089.61035 / 444.66577 	Train/Val Acc:  99.84 / 91.85
Epoch:  16 	Train/Val Loss:  2089.5625 / 444.38913 	Train/Val Acc:  99.84 / 91.83
Epoch:  17 	Train/Val Loss:  2089.60547 / 444.68546 	Train/Val Acc:  99.82 / 91.77
Epoch:  18 	Train/Val Loss:  2089.62402 / 444.71545 	Train/Val Acc:  99.83 / 91.89
Epoch:  19 	Train/Val Loss:  2089.51318 / 445.12628 	Train/Val Acc:  99.84 / 91.79
Epoch:  20 	Train/Val Loss:  2089.56812 / 445.19205 	Train/Val Acc:  99.82 / 91.78
Epoch:  21 	Train/Val Loss:  2089.41797 / 445.59067 	Train/Val Acc:  99.84 / 91.83
Epoch:  22 	Train/Val Loss:  2089.28711 / 445.26355 	Train/Val Acc:  99.83 / 91.66
Epoch:  23 	Train/Val Loss:  2089.37329 / 445.45392 	Train/Val Acc:  99.86 / 91.74
Epoch:  24 	Train/Val Loss:  2089.26099 / 445.28024 	Train/Val Acc:  99.87 / 91.66
Epoch:  25 	Train/Val Loss:  2089.33618 / 445.82465 	Train/Val Acc:  99.87 / 91.64
Epoch:  26 	Train/Val Loss:  2089.4895 / 445.93597 	Train/Val Acc:  99.85 / 91.71
Epoch:  27 	Train/Val Loss:  2089.35913 / 445.77689 	Train/Val Acc:  99.86 / 91.68
Epoch:  28 	Train/Val Loss:  2089.36865 / 445.85953 	Train/Val Acc:  99.86 / 91.74
Epoch:  29 	Train/Val Loss:  2089.31201 / 445.59247 	Train/Val Acc:  99.87 / 91.65
Epoch:  30 	Train/Val Loss:  2089.47192 / 446.05984 	Train/Val Acc:  99.84 / 91.67
Epoch:  31 	Train/Val Loss:  2089.30005 / 446.08463 	Train/Val Acc:  99.85 / 91.68
Epoch:  32 	Train/Val Loss:  2089.38647 / 446.25739 	Train/Val Acc:  99.86 / 91.68
Epoch:  33 	Train/Val Loss:  2089.50366 / 446.18066 	Train/Val Acc:  99.84 / 91.73
Epoch:  34 	Train/Val Loss:  2089.4314 / 446.07889 	Train/Val Acc:  99.84 / 91.67
Epoch:  35 	Train/Val Loss:  2089.24048 / 446.18552 	Train/Val Acc:  99.87 / 91.67
Epoch:  36 	Train/Val Loss:  2089.29492 / 446.48215 	Train/Val Acc:  99.87 / 91.64
Epoch:  37 	Train/Val Loss:  2089.23096 / 446.22147 	Train/Val Acc:  99.86 / 91.66
Epoch:  38 	Train/Val Loss:  2089.3894 / 446.37964 	Train/Val Acc:  99.86 / 91.69
Epoch:  39 	Train/Val Loss:  2089.4353 / 446.33295 	Train/Val Acc:  99.83 / 91.68
Epoch:  40 	Train/Val Loss:  2089.43359 / 446.43323 	Train/Val Acc:  99.83 / 91.68
Epoch:  41 	Train/Val Loss:  2089.39746 / 446.4292 	Train/Val Acc:  99.86 / 91.54
Epoch:  42 	Train/Val Loss:  2089.39673 / 446.54749 	Train/Val Acc:  99.84 / 91.53
Epoch:  43 	Train/Val Loss:  2089.22339 / 446.49744 	Train/Val Acc:  99.86 / 91.4
Epoch:  44 	Train/Val Loss:  2089.55591 / 446.4613 	Train/Val Acc:  99.81 / 91.46
Epoch:  45 	Train/Val Loss:  2089.52441 / 446.82562 	Train/Val Acc:  99.83 / 91.29
Epoch:  46 	Train/Val Loss:  2089.17578 / 446.48135 	Train/Val Acc:  99.89 / 91.44
Epoch:  47 	Train/Val Loss:  2089.41968 / 446.33774 	Train/Val Acc:  99.83 / 91.61
Epoch:  48 	Train/Val Loss:  2089.12842 / 446.51175 	Train/Val Acc:  99.87 / 91.52
Epoch:  49 	Train/Val Loss:  2089.16089 / 446.4791 	Train/Val Acc:  99.86 / 91.52
Epoch:  50 	Train/Val Loss:  2089.27759 / 446.22711 	Train/Val Acc:  99.85 / 91.53
Epoch:  51 	Train/Val Loss:  2089.08423 / 446.39316 	Train/Val Acc:  99.9 / 91.61
Epoch:  52 	Train/Val Loss:  2089.28394 / 446.36282 	Train/Val Acc:  99.86 / 91.58
Epoch:  53 	Train/Val Loss:  2089.29321 / 446.5148 	Train/Val Acc:  99.86 / 91.45
Epoch:  54 	Train/Val Loss:  2089.37769 / 446.23755 	Train/Val Acc:  99.86 / 91.63
Epoch:  55 	Train/Val Loss:  2089.24414 / 446.41641 	Train/Val Acc:  99.86 / 91.66
Epoch:  56 	Train/Val Loss:  2089.28052 / 446.48502 	Train/Val Acc:  99.85 / 91.53
Epoch:  57 	Train/Val Loss:  2089.12939 / 446.23026 	Train/Val Acc:  99.88 / 91.66
Epoch:  58 	Train/Val Loss:  2089.27051 / 446.5134 	Train/Val Acc:  99.85 / 91.68
Epoch:  59 	Train/Val Loss:  2089.30737 / 446.65308 	Train/Val Acc:  99.87 / 91.62
Epoch:  60 	Train/Val Loss:  2089.15552 / 446.36453 	Train/Val Acc:  99.87 / 91.7
Epoch:  61 	Train/Val Loss:  2089.14575 / 446.46545 	Train/Val Acc:  99.89 / 91.66
Epoch:  62 	Train/Val Loss:  2089.11108 / 446.28775 	Train/Val Acc:  99.89 / 91.65
Epoch:  63 	Train/Val Loss:  2089.19287 / 446.43332 	Train/Val Acc:  99.88 / 91.67
Epoch:  64 	Train/Val Loss:  2089.27759 / 446.42023 	Train/Val Acc:  99.85 / 91.69
Epoch:  65 	Train/Val Loss:  2089.44312 / 446.30939 	Train/Val Acc:  99.83 / 91.58
Epoch:  66 	Train/Val Loss:  2089.10474 / 446.39621 	Train/Val Acc:  99.87 / 91.69
Epoch:  67 	Train/Val Loss:  2089.22461 / 446.29324 	Train/Val Acc:  99.87 / 91.61
Epoch:  68 	Train/Val Loss:  2089.22168 / 446.51315 	Train/Val Acc:  99.87 / 91.61
Epoch:  69 	Train/Val Loss:  2089.27417 / 446.7373 	Train/Val Acc:  99.86 / 91.67
Epoch:  70 	Train/Val Loss:  2089.13672 / 446.4798 	Train/Val Acc:  99.87 / 91.68
Epoch:  71 	Train/Val Loss:  2089.12842 / 446.56744 	Train/Val Acc:  99.89 / 91.56
Epoch:  72 	Train/Val Loss:  2089.1853 / 446.39636 	Train/Val Acc:  99.86 / 91.54
Epoch:  73 	Train/Val Loss:  2089.26489 / 446.52609 	Train/Val Acc:  99.84 / 91.54
Epoch:  74 	Train/Val Loss:  2089.2085 / 446.5788 	Train/Val Acc:  99.86 / 91.71
Epoch:  75 	Train/Val Loss:  2089.17188 / 446.76044 	Train/Val Acc:  99.88 / 91.57
Epoch:  76 	Train/Val Loss:  2089.2605 / 446.21677 	Train/Val Acc:  99.86 / 91.67
Epoch:  77 	Train/Val Loss:  2089.25781 / 446.46545 	Train/Val Acc:  99.86 / 91.67
Epoch:  78 	Train/Val Loss:  2089.34253 / 446.45041 	Train/Val Acc:  99.85 / 91.5
Epoch:  79 	Train/Val Loss:  2089.38184 / 446.50729 	Train/Val Acc:  99.85 / 91.58
Epoch:  80 	Train/Val Loss:  2089.23047 / 446.29395 	Train/Val Acc:  99.87 / 91.58
Epoch:  81 	Train/Val Loss:  2089.21509 / 446.40262 	Train/Val Acc:  99.86 / 91.66
Epoch:  82 	Train/Val Loss:  2089.19873 / 446.31665 	Train/Val Acc:  99.87 / 91.65
Epoch:  83 	Train/Val Loss:  2089.09058 / 446.39362 	Train/Val Acc:  99.88 / 91.51
Epoch:  84 	Train/Val Loss:  2089.20215 / 446.43277 	Train/Val Acc:  99.87 / 91.65
Epoch:  85 	Train/Val Loss:  2089.23682 / 446.44617 	Train/Val Acc:  99.87 / 91.6
Epoch:  86 	Train/Val Loss:  2089.28687 / 446.23724 	Train/Val Acc:  99.86 / 91.75
Epoch:  87 	Train/Val Loss:  2089.26611 / 446.36142 	Train/Val Acc:  99.9 / 91.61
Epoch:  88 	Train/Val Loss:  2089.16431 / 446.35931 	Train/Val Acc:  99.88 / 91.66
Epoch:  89 	Train/Val Loss:  2089.12036 / 446.39362 	Train/Val Acc:  99.89 / 91.69
Epoch:  90 	Train/Val Loss:  2088.92944 / 446.57623 	Train/Val Acc:  99.91 / 91.64
Epoch:  91 	Train/Val Loss:  2089.10181 / 446.57419 	Train/Val Acc:  99.89 / 91.64
Epoch:  92 	Train/Val Loss:  2089.21167 / 446.42581 	Train/Val Acc:  99.87 / 91.67
Epoch:  93 	Train/Val Loss:  2089.21997 / 446.40567 	Train/Val Acc:  99.86 / 91.54
Epoch:  94 	Train/Val Loss:  2089.14453 / 446.37091 	Train/Val Acc:  99.87 / 91.61
Epoch:  95 	Train/Val Loss:  2089.12744 / 446.46616 	Train/Val Acc:  99.88 / 91.53
Epoch:  96 	Train/Val Loss:  2089.11304 / 446.43701 	Train/Val Acc:  99.87 / 91.65
Epoch:  97 	Train/Val Loss:  2089.06128 / 446.25449 	Train/Val Acc:  99.88 / 91.61
Epoch:  98 	Train/Val Loss:  2089.20752 / 446.21457 	Train/Val Acc:  99.86 / 91.64
Epoch:  99 	Train/Val Loss:  2089.10791 / 446.44772 	Train/Val Acc:  99.88 / 91.68
Testing on Rank 2
Testing on Rank 1
Epoch:  100 	Train/Val Loss:  2089.24438 / 446.39572 	Train/Val Acc:  99.86 / 91.58
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 115824... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁▁▁▁▁▁█▁▃▁▁▃▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:                                   Train Acc ▃▄▅▅▆▃▃▂▃▄▃▅▄▃▅▃▄▁▇▅█▅▄▅▇▄▆▅▄▅▅▄▅▆█▇▆▅▆▅
wandb:                                  Train Loss █▇▇▅▅▅▅▆▄▄▅▄▃▄▃▄▄▅▂▂▁▄▃▃▂▃▂▃▂▂▃▄▂▂▃▂▂▂▁▃
wandb:                                     Val Acc ▆▆▇██▇▇▇▇▄▅▄▄▄▄▄▂▁▃▂▃▄▄▃▄▃▃▄▂▃▄▃▂▃▄▄▂▂▄▃
wandb:                                    Val Loss ▁▁▂▂▃▄▄▅▆▆▇▆▇▇█▇██▇█▇▇▇█▇▇▇█▇██▇▇█▇█▇█▇▇
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 449795449683968.0
wandb:                                     Val Acc 0.91582
wandb:                                    Val Loss 446.39572
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced brisk-mountain-6: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/3hpgqvww
wandb: Find logs at: ./wandb/run-20220109_222700-3hpgqvww/logs/debug.log
wandb: 

WandB Finished
Run Complete
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-10 00:17:39.013341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-10 00:17:39.018236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run colorful-lion-13
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/dl3f0h2c
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220110_001737-dl3f0h2c
wandb: Run `wandb offline` to turn off syncing.

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 2
Training on Rank 0
Training on Rank 1
Epoch:  1 	Train/Val Loss:  2089.85229 / 442.22879 	Train/Val Acc:  99.86 / 91.93
Epoch:  2 	Train/Val Loss:  2089.91406 / 442.18088 	Train/Val Acc:  99.84 / 91.98
Epoch:  3 	Train/Val Loss:  2089.77905 / 442.36511 	Train/Val Acc:  99.87 / 91.71
Epoch:  4 	Train/Val Loss:  2089.67896 / 441.9584 	Train/Val Acc:  99.85 / 91.98
Epoch:  5 	Train/Val Loss:  2089.87207 / 442.19077 	Train/Val Acc:  99.84 / 91.89
Epoch:  6 	Train/Val Loss:  2089.76562 / 442.20831 	Train/Val Acc:  99.87 / 91.85
Epoch:  7 	Train/Val Loss:  2089.88257 / 442.26926 	Train/Val Acc:  99.82 / 91.83
Epoch:  8 	Train/Val Loss:  2089.74219 / 442.21707 	Train/Val Acc:  99.86 / 91.92
Epoch:  9 	Train/Val Loss:  2089.71533 / 442.31982 	Train/Val Acc:  99.85 / 91.84
[lambda01:894475] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:893656] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 17
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 241
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 237
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 82
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 140
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 86
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 201
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 129
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 102
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 198
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 69
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 74
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 81
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 70
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 128
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 128
Epoch:  10 	Train/Val Loss:  2089.87842 / 442.35364 	Train/Val Acc:  99.86 / 91.92
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 114
Epoch:  11 	Train/Val Loss:  2089.79858 / 442.43622 	Train/Val Acc:  99.85 / 91.89
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 223
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 91
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 155
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 42
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 141
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 197
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 138
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 59
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 40
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 114
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 88
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 41
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 128
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 66
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 89
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 128
[lambda01][[3746,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(24) failed: Connection reset by peer (104)
Epoch:  12 	Train/Val Loss:  2089.7522 / 442.58047 	Train/Val Acc:  99.85 / 91.81
Epoch:  13 	Train/Val Loss:  2089.7666 / 442.29324 	Train/Val Acc:  99.86 / 91.94
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 240
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 255
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 47
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 205
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 189
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 101
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 116
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 128
[lambda01][[54931,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(23) failed: Connection reset by peer (104)
[lambda01][[54727,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(23) failed: Connection reset by peer (104)
Epoch:  14 	Train/Val Loss:  2089.74854 / 442.44446 	Train/Val Acc:  99.87 / 92.07
Epoch:  15 	Train/Val Loss:  2089.85913 / 442.59039 	Train/Val Acc:  99.83 / 91.91
Epoch:  16 	Train/Val Loss:  2089.88989 / 442.40982 	Train/Val Acc:  99.82 / 91.94
[lambda01][[33368,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(18) failed: Connection reset by peer (104)
Epoch:  17 	Train/Val Loss:  2089.70776 / 442.5159 	Train/Val Acc:  99.87 / 91.99
[lambda01][[44035,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(18) failed: Connection reset by peer (104)
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 100
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 100
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 58
Epoch:  18 	Train/Val Loss:  2089.72046 / 442.46896 	Train/Val Acc:  99.86 / 91.94
[lambda01:115568] tcp_peer_recv_connect_ack: invalid header type: 99
[lambda01:828760] tcp_peer_recv_connect_ack: invalid header type: 99
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 100
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 99
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 100
[lambda01:828756] tcp_peer_recv_connect_ack: invalid header type: 99
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 100
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:828757] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 99
Epoch:  19 	Train/Val Loss:  2089.70312 / 442.63177 	Train/Val Acc:  99.85 / 91.88
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 58
[lambda01:828850] tcp_peer_recv_connect_ack: invalid header type: 58
Epoch:  20 	Train/Val Loss:  2089.68335 / 442.56274 	Train/Val Acc:  99.85 / 91.95
Epoch:  21 	Train/Val Loss:  2089.82593 / 443.08188 	Train/Val Acc:  99.82 / 91.84
Epoch:  22 	Train/Val Loss:  2089.79224 / 442.76379 	Train/Val Acc:  99.84 / 91.88
Epoch:  23 	Train/Val Loss:  2089.57495 / 442.78571 	Train/Val Acc:  99.86 / 91.94
Epoch:  24 	Train/Val Loss:  2089.7356 / 442.63187 	Train/Val Acc:  99.85 / 91.92
Epoch:  25 	Train/Val Loss:  2089.6106 / 443.02679 	Train/Val Acc:  99.85 / 91.83
Epoch:  26 	Train/Val Loss:  2089.65698 / 442.97821 	Train/Val Acc:  99.86 / 91.9
Epoch:  27 	Train/Val Loss:  2089.63696 / 443.06888 	Train/Val Acc:  99.85 / 91.77
Epoch:  28 	Train/Val Loss:  2089.68115 / 443.29434 	Train/Val Acc:  99.85 / 91.85
Epoch:  29 	Train/Val Loss:  2089.65869 / 443.0018 	Train/Val Acc:  99.84 / 91.77
Epoch:  30 	Train/Val Loss:  2089.67383 / 443.25101 	Train/Val Acc:  99.84 / 91.9
Epoch:  31 	Train/Val Loss:  2089.72119 / 443.14706 	Train/Val Acc:  99.85 / 91.94
Epoch:  32 	Train/Val Loss:  2089.72705 / 443.23911 	Train/Val Acc:  99.85 / 91.93
Epoch:  33 	Train/Val Loss:  2089.74414 / 443.20767 	Train/Val Acc:  99.81 / 91.85
Epoch:  34 	Train/Val Loss:  2089.66675 / 443.07529 	Train/Val Acc:  99.85 / 91.92
Epoch:  35 	Train/Val Loss:  2089.89844 / 443.15363 	Train/Val Acc:  99.82 / 91.82
Epoch:  36 	Train/Val Loss:  2089.60107 / 443.39197 	Train/Val Acc:  99.84 / 91.81
Epoch:  37 	Train/Val Loss:  2089.64111 / 443.17416 	Train/Val Acc:  99.87 / 91.79
Epoch:  38 	Train/Val Loss:  2089.59619 / 443.25485 	Train/Val Acc:  99.84 / 91.94
Epoch:  39 	Train/Val Loss:  2089.6394 / 443.39548 	Train/Val Acc:  99.84 / 91.89
Epoch:  40 	Train/Val Loss:  2089.48535 / 443.42972 	Train/Val Acc:  99.85 / 91.96
Epoch:  41 	Train/Val Loss:  2089.67505 / 443.60559 	Train/Val Acc:  99.82 / 91.76
Epoch:  42 	Train/Val Loss:  2089.72437 / 443.58853 	Train/Val Acc:  99.82 / 91.92
Epoch:  43 	Train/Val Loss:  2089.60083 / 443.69391 	Train/Val Acc:  99.85 / 91.8
Epoch:  44 	Train/Val Loss:  2089.45239 / 443.35852 	Train/Val Acc:  99.88 / 91.86
Epoch:  45 	Train/Val Loss:  2089.53223 / 443.74234 	Train/Val Acc:  99.87 / 91.71
Epoch:  46 	Train/Val Loss:  2089.54468 / 443.75266 	Train/Val Acc:  99.84 / 91.82
Epoch:  47 	Train/Val Loss:  2089.55884 / 443.84464 	Train/Val Acc:  99.85 / 91.92
Epoch:  48 	Train/Val Loss:  2089.44165 / 443.9053 	Train/Val Acc:  99.86 / 91.74
Epoch:  49 	Train/Val Loss:  2089.53101 / 443.63977 	Train/Val Acc:  99.85 / 91.84
Epoch:  50 	Train/Val Loss:  2089.4812 / 443.81665 	Train/Val Acc:  99.89 / 91.72
Epoch:  51 	Train/Val Loss:  2089.41187 / 443.73871 	Train/Val Acc:  99.86 / 91.96
Epoch:  52 	Train/Val Loss:  2089.38696 / 443.75226 	Train/Val Acc:  99.85 / 91.87
Epoch:  53 	Train/Val Loss:  2089.41748 / 444.0257 	Train/Val Acc:  99.86 / 91.67
Epoch:  54 	Train/Val Loss:  2089.46802 / 443.84824 	Train/Val Acc:  99.86 / 91.88
Epoch:  55 	Train/Val Loss:  2089.64185 / 443.84244 	Train/Val Acc:  99.85 / 91.85
Epoch:  56 	Train/Val Loss:  2089.47925 / 443.98419 	Train/Val Acc:  99.86 / 91.89
Epoch:  57 	Train/Val Loss:  2089.44385 / 443.88583 	Train/Val Acc:  99.87 / 91.98
Epoch:  58 	Train/Val Loss:  2089.47314 / 443.92203 	Train/Val Acc:  99.87 / 91.95
Epoch:  59 	Train/Val Loss:  2089.47241 / 444.14008 	Train/Val Acc:  99.86 / 91.75
Epoch:  60 	Train/Val Loss:  2089.49219 / 444.00165 	Train/Val Acc:  99.88 / 91.95
Epoch:  61 	Train/Val Loss:  2089.45923 / 444.07004 	Train/Val Acc:  99.86 / 91.83
Epoch:  62 	Train/Val Loss:  2089.44995 / 443.87607 	Train/Val Acc:  99.86 / 91.83
Epoch:  63 	Train/Val Loss:  2089.55249 / 444.12604 	Train/Val Acc:  99.83 / 91.78
Epoch:  64 	Train/Val Loss:  2089.35791 / 444.07684 	Train/Val Acc:  99.87 / 91.93
Epoch:  65 	Train/Val Loss:  2089.60083 / 444.02921 	Train/Val Acc:  99.83 / 91.95
Epoch:  66 	Train/Val Loss:  2089.40088 / 443.96707 	Train/Val Acc:  99.86 / 91.89
Epoch:  67 	Train/Val Loss:  2089.47705 / 443.97171 	Train/Val Acc:  99.85 / 91.79
Epoch:  68 	Train/Val Loss:  2089.46631 / 444.22705 	Train/Val Acc:  99.85 / 91.91
Epoch:  69 	Train/Val Loss:  2089.44214 / 444.46741 	Train/Val Acc:  99.86 / 91.81
Epoch:  70 	Train/Val Loss:  2089.52783 / 444.3038 	Train/Val Acc:  99.82 / 91.8
Epoch:  71 	Train/Val Loss:  2089.40625 / 444.31277 	Train/Val Acc:  99.87 / 91.91
Epoch:  72 	Train/Val Loss:  2089.48291 / 444.19028 	Train/Val Acc:  99.88 / 91.8
Epoch:  73 	Train/Val Loss:  2089.48389 / 444.31815 	Train/Val Acc:  99.85 / 91.83
Epoch:  74 	Train/Val Loss:  2089.43433 / 444.31314 	Train/Val Acc:  99.86 / 91.91
Epoch:  75 	Train/Val Loss:  2089.28516 / 444.38724 	Train/Val Acc:  99.88 / 91.79
Epoch:  76 	Train/Val Loss:  2089.49487 / 443.97867 	Train/Val Acc:  99.85 / 92.01
Epoch:  77 	Train/Val Loss:  2089.42578 / 444.28845 	Train/Val Acc:  99.85 / 91.82
Epoch:  78 	Train/Val Loss:  2089.43896 / 444.24014 	Train/Val Acc:  99.85 / 91.84
Epoch:  79 	Train/Val Loss:  2089.44629 / 444.20917 	Train/Val Acc:  99.86 / 91.72
Epoch:  80 	Train/Val Loss:  2089.24609 / 444.04739 	Train/Val Acc:  99.89 / 91.88
Epoch:  81 	Train/Val Loss:  2089.36548 / 444.34644 	Train/Val Acc:  99.87 / 91.84
Epoch:  82 	Train/Val Loss:  2089.50854 / 444.37576 	Train/Val Acc:  99.85 / 91.88
Epoch:  83 	Train/Val Loss:  2089.5813 / 444.31949 	Train/Val Acc:  99.83 / 91.89
Epoch:  84 	Train/Val Loss:  2089.47778 / 444.24677 	Train/Val Acc:  99.84 / 91.92
Epoch:  85 	Train/Val Loss:  2089.5686 / 444.45715 	Train/Val Acc:  99.85 / 91.87
Epoch:  86 	Train/Val Loss:  2089.51782 / 444.35132 	Train/Val Acc:  99.85 / 91.92
Epoch:  87 	Train/Val Loss:  2089.48584 / 444.3017 	Train/Val Acc:  99.84 / 91.73
Epoch:  88 	Train/Val Loss:  2089.45264 / 444.42645 	Train/Val Acc:  99.84 / 91.8
Epoch:  89 	Train/Val Loss:  2089.36084 / 444.28195 	Train/Val Acc:  99.86 / 91.83
Epoch:  90 	Train/Val Loss:  2089.33911 / 444.58429 	Train/Val Acc:  99.87 / 91.88
Epoch:  91 	Train/Val Loss:  2089.37744 / 444.66541 	Train/Val Acc:  99.86 / 91.91
Epoch:  92 	Train/Val Loss:  2089.37891 / 444.4715 	Train/Val Acc:  99.87 / 91.84
Epoch:  93 	Train/Val Loss:  2089.55957 / 444.39478 	Train/Val Acc:  99.85 / 91.77
Epoch:  94 	Train/Val Loss:  2089.4397 / 444.37582 	Train/Val Acc:  99.86 / 91.85
Epoch:  95 	Train/Val Loss:  2089.40552 / 444.41138 	Train/Val Acc:  99.86 / 91.69
Epoch:  96 	Train/Val Loss:  2089.34839 / 444.58414 	Train/Val Acc:  99.86 / 91.8
Epoch:  97 	Train/Val Loss:  2089.47119 / 444.32544 	Train/Val Acc:  99.85 / 91.93
Epoch:  98 	Train/Val Loss:  2089.32788 / 444.21884 	Train/Val Acc:  99.88 / 91.78
Epoch:  99 	Train/Val Loss:  2089.47266 / 444.28696 	Train/Val Acc:  99.87 / 91.91
Testing on Rank 1
Testing on Rank 2
Epoch:  100 	Train/Val Loss:  2089.56567 / 444.33859 	Train/Val Acc:  99.85 / 91.86
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
[lambda01][[31875,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(22) failed: Connection reset by peer (104)
[lambda01][[31875,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(82) failed: Connection reset by peer (104)
[lambda01][[31875,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(83) failed: Connection reset by peer (104)
[lambda01][[31875,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(84) failed: Connection reset by peer (104)
[lambda01][[31875,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(90) failed: Connection reset by peer (104)
[lambda01][[31875,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(91) failed: Connection reset by peer (104)
[lambda01][[31886,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(22) failed: Connection reset by peer (104)
[lambda01][[31886,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(82) failed: Connection reset by peer (104)
[lambda01][[31886,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(83) failed: Connection reset by peer (104)
[lambda01][[31886,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(84) failed: Connection reset by peer (104)
[lambda01][[31886,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(90) failed: Connection reset by peer (104)
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 828781... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
[lambda01][[31844,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(59) failed: Connection reset by peer (104)
[lambda01][[31844,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(60) failed: Connection reset by peer (104)
[lambda01][[31844,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(61) failed: Connection reset by peer (104)
[lambda01][[31844,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(67) failed: Connection reset by peer (104)
[lambda01][[31844,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(24) failed: Connection reset by peer (104)
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁
wandb:                                   Train Acc ▆▆▇▆▄▅▁▆▁▆▆▅▄▅▄▄▂█▄▅▅▆▆▆▆▇▄▆█▅▄▅▅▃▄▆▆▆▅▄
wandb:                                  Train Loss █▇▆▆▇▆█▆▇▄▅▅▆▅▄▅▅▂▃▃▂▂▃▃▂▁▃▂▃▂▂▂▃▃▃▁▁▂▂▄
wandb:                                     Val Acc ▇▁▅▇▆▇▇▇▅▇▆▃▇▇▄▆▇▅▇▅▅▆█▂▄▇▃▄▄▃▄▆▆▅▄▆▃▁▃▅
wandb:                                    Val Loss ▁▁▁▁▂▁▂▂▄▂▃▃▄▄▄▄▅▄▆▅▆▆▆▇▆▆▆▇▇▇▇▆▇███▇▇▇▇
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 1282823815168.0
wandb:                                     Val Acc 0.91862
wandb:                                    Val Loss 444.33859
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced colorful-lion-13: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/dl3f0h2c
wandb: Find logs at: ./wandb/run-20220110_001737-dl3f0h2c/logs/debug.log
wandb: 

WandB Finished
[lambda01][[31874,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(46) failed: Connection reset by peer (104)
[lambda01][[31874,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(22) failed: Connection reset by peer (104)
[lambda01][[31874,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(38) failed: Connection reset by peer (104)
[lambda01][[31874,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(39) failed: Connection reset by peer (104)
[lambda01][[31874,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(40) failed: Connection reset by peer (104)
Run Complete
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-10 02:06:58.751088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-10 02:06:58.755746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run fast-energy-14
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/4q8mivns
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220110_020657-4q8mivns
wandb: Run `wandb offline` to turn off syncing.
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 1
Training on Rank 0
Training on Rank 2
Epoch:  1 	Train/Val Loss:  2089.82422 / 442.26224 	Train/Val Acc:  99.85 / 91.8
Epoch:  2 	Train/Val Loss:  2089.80054 / 442.18536 	Train/Val Acc:  99.85 / 92.04
Epoch:  3 	Train/Val Loss:  2089.99219 / 442.25769 	Train/Val Acc:  99.82 / 91.8
Epoch:  4 	Train/Val Loss:  2089.83032 / 441.97174 	Train/Val Acc:  99.84 / 91.95
Epoch:  5 	Train/Val Loss:  2089.85547 / 442.13724 	Train/Val Acc:  99.87 / 91.91
Epoch:  6 	Train/Val Loss:  2089.95312 / 442.15402 	Train/Val Acc:  99.83 / 91.83
Epoch:  7 	Train/Val Loss:  2089.78564 / 442.12921 	Train/Val Acc:  99.87 / 91.87
Epoch:  8 	Train/Val Loss:  2089.73633 / 442.12589 	Train/Val Acc:  99.86 / 91.92
Epoch:  9 	Train/Val Loss:  2089.86914 / 442.17877 	Train/Val Acc:  99.84 / 91.85
Epoch:  10 	Train/Val Loss:  2089.83447 / 442.23032 	Train/Val Acc:  99.85 / 91.87
Epoch:  11 	Train/Val Loss:  2089.90527 / 442.14386 	Train/Val Acc:  99.84 / 91.91
Epoch:  12 	Train/Val Loss:  2089.77881 / 442.32288 	Train/Val Acc:  99.87 / 91.84
Epoch:  13 	Train/Val Loss:  2089.80005 / 442.08948 	Train/Val Acc:  99.86 / 92.01
Epoch:  14 	Train/Val Loss:  2089.86426 / 442.21506 	Train/Val Acc:  99.84 / 92.04
Epoch:  15 	Train/Val Loss:  2089.81812 / 442.44611 	Train/Val Acc:  99.85 / 91.79
Epoch:  16 	Train/Val Loss:  2090.15332 / 442.11969 	Train/Val Acc:  99.8 / 91.93
Epoch:  17 	Train/Val Loss:  2089.65503 / 442.25916 	Train/Val Acc:  99.9 / 92.03
Epoch:  18 	Train/Val Loss:  2089.78052 / 442.14828 	Train/Val Acc:  99.86 / 91.91
Epoch:  19 	Train/Val Loss:  2089.82397 / 442.27704 	Train/Val Acc:  99.88 / 91.84
Epoch:  20 	Train/Val Loss:  2089.65894 / 442.23105 	Train/Val Acc:  99.87 / 91.84
Epoch:  21 	Train/Val Loss:  2089.88354 / 442.54828 	Train/Val Acc:  99.84 / 91.91
Epoch:  22 	Train/Val Loss:  2089.89673 / 442.15012 	Train/Val Acc:  99.84 / 91.96
Epoch:  23 	Train/Val Loss:  2089.76343 / 442.21829 	Train/Val Acc:  99.88 / 91.98
Epoch:  24 	Train/Val Loss:  2089.82397 / 441.99106 	Train/Val Acc:  99.85 / 91.85
Epoch:  25 	Train/Val Loss:  2089.80371 / 442.33643 	Train/Val Acc:  99.85 / 91.87
Epoch:  26 	Train/Val Loss:  2089.86914 / 442.34207 	Train/Val Acc:  99.83 / 91.9
Epoch:  27 	Train/Val Loss:  2089.8252 / 442.38702 	Train/Val Acc:  99.85 / 91.83
Epoch:  28 	Train/Val Loss:  2089.91797 / 442.41937 	Train/Val Acc:  99.83 / 91.83
Epoch:  29 	Train/Val Loss:  2089.75 / 442.11298 	Train/Val Acc:  99.88 / 91.79
Epoch:  30 	Train/Val Loss:  2089.79565 / 442.36337 	Train/Val Acc:  99.87 / 92.0
Epoch:  31 	Train/Val Loss:  2089.67383 / 442.32364 	Train/Val Acc:  99.88 / 91.91
Epoch:  32 	Train/Val Loss:  2089.76904 / 442.20435 	Train/Val Acc:  99.87 / 92.0
Epoch:  33 	Train/Val Loss:  2089.77197 / 442.24286 	Train/Val Acc:  99.86 / 91.86
Epoch:  34 	Train/Val Loss:  2089.85034 / 442.24411 	Train/Val Acc:  99.84 / 91.98
Epoch:  35 	Train/Val Loss:  2089.85815 / 442.14432 	Train/Val Acc:  99.87 / 91.91
Epoch:  36 	Train/Val Loss:  2089.65747 / 442.33163 	Train/Val Acc:  99.86 / 91.96
Epoch:  37 	Train/Val Loss:  2089.80518 / 442.20651 	Train/Val Acc:  99.86 / 91.75
Epoch:  38 	Train/Val Loss:  2089.8418 / 442.16055 	Train/Val Acc:  99.86 / 91.95
Epoch:  39 	Train/Val Loss:  2089.64648 / 442.22195 	Train/Val Acc:  99.89 / 91.9
Epoch:  40 	Train/Val Loss:  2089.81616 / 442.36954 	Train/Val Acc:  99.86 / 91.86
Epoch:  41 	Train/Val Loss:  2089.82837 / 442.54428 	Train/Val Acc:  99.84 / 91.81
Epoch:  42 	Train/Val Loss:  2089.7439 / 442.29794 	Train/Val Acc:  99.86 / 91.93
Epoch:  43 	Train/Val Loss:  2089.81323 / 442.51926 	Train/Val Acc:  99.84 / 91.91
Epoch:  44 	Train/Val Loss:  2089.78882 / 442.19586 	Train/Val Acc:  99.86 / 91.89
Epoch:  45 	Train/Val Loss:  2089.80005 / 442.49475 	Train/Val Acc:  99.84 / 91.67
Epoch:  46 	Train/Val Loss:  2089.91333 / 442.5065 	Train/Val Acc:  99.83 / 91.99
Epoch:  47 	Train/Val Loss:  2089.91406 / 442.40137 	Train/Val Acc:  99.84 / 91.89
Epoch:  48 	Train/Val Loss:  2089.87622 / 442.5661 	Train/Val Acc:  99.85 / 91.79
Epoch:  49 	Train/Val Loss:  2089.8042 / 442.26489 	Train/Val Acc:  99.84 / 91.95
Epoch:  50 	Train/Val Loss:  2089.81396 / 442.32233 	Train/Val Acc:  99.84 / 91.86
Epoch:  51 	Train/Val Loss:  2089.85229 / 442.26514 	Train/Val Acc:  99.86 / 91.86
Epoch:  52 	Train/Val Loss:  2089.70581 / 442.23645 	Train/Val Acc:  99.86 / 91.94
Epoch:  53 	Train/Val Loss:  2089.74658 / 442.57758 	Train/Val Acc:  99.86 / 91.74
Epoch:  54 	Train/Val Loss:  2089.81519 / 442.30908 	Train/Val Acc:  99.84 / 91.93
Epoch:  55 	Train/Val Loss:  2089.91699 / 442.45621 	Train/Val Acc:  99.85 / 91.94
Epoch:  56 	Train/Val Loss:  2089.7041 / 442.38583 	Train/Val Acc:  99.86 / 92.03
Epoch:  57 	Train/Val Loss:  2089.81567 / 442.29974 	Train/Val Acc:  99.85 / 92.07
Epoch:  58 	Train/Val Loss:  2089.74658 / 442.32309 	Train/Val Acc:  99.83 / 91.93
Epoch:  59 	Train/Val Loss:  2089.71973 / 442.47342 	Train/Val Acc:  99.86 / 91.95
Epoch:  60 	Train/Val Loss:  2089.71313 / 442.39774 	Train/Val Acc:  99.86 / 91.93
Epoch:  61 	Train/Val Loss:  2089.70386 / 442.38843 	Train/Val Acc:  99.86 / 91.97
Epoch:  62 	Train/Val Loss:  2089.72461 / 442.37833 	Train/Val Acc:  99.87 / 91.94
Epoch:  63 	Train/Val Loss:  2089.75879 / 442.44843 	Train/Val Acc:  99.86 / 91.84
Epoch:  64 	Train/Val Loss:  2089.86987 / 442.51025 	Train/Val Acc:  99.86 / 91.96
Epoch:  65 	Train/Val Loss:  2089.79736 / 442.34274 	Train/Val Acc:  99.86 / 91.9
Epoch:  66 	Train/Val Loss:  2089.75928 / 442.33594 	Train/Val Acc:  99.83 / 91.9
Epoch:  67 	Train/Val Loss:  2089.7644 / 442.2977 	Train/Val Acc:  99.85 / 91.92
Epoch:  68 	Train/Val Loss:  2089.8623 / 442.56088 	Train/Val Acc:  99.83 / 91.96
Epoch:  69 	Train/Val Loss:  2089.75269 / 442.63257 	Train/Val Acc:  99.86 / 91.86
Epoch:  70 	Train/Val Loss:  2089.90894 / 442.45642 	Train/Val Acc:  99.84 / 91.91
Epoch:  71 	Train/Val Loss:  2089.81592 / 442.50366 	Train/Val Acc:  99.84 / 91.9
Epoch:  72 	Train/Val Loss:  2089.79395 / 442.556 	Train/Val Acc:  99.84 / 91.85
Epoch:  73 	Train/Val Loss:  2089.84741 / 442.54745 	Train/Val Acc:  99.86 / 91.81
Epoch:  74 	Train/Val Loss:  2089.81934 / 442.56003 	Train/Val Acc:  99.86 / 92.01
Epoch:  75 	Train/Val Loss:  2089.67285 / 442.57394 	Train/Val Acc:  99.86 / 91.85
Epoch:  76 	Train/Val Loss:  2089.75757 / 442.0358 	Train/Val Acc:  99.86 / 92.03
Epoch:  77 	Train/Val Loss:  2089.62305 / 442.50171 	Train/Val Acc:  99.89 / 91.85
Epoch:  78 	Train/Val Loss:  2089.8562 / 442.47476 	Train/Val Acc:  99.85 / 91.92
Epoch:  79 	Train/Val Loss:  2089.88208 / 442.42526 	Train/Val Acc:  99.84 / 91.85
Epoch:  80 	Train/Val Loss:  2089.64453 / 442.21375 	Train/Val Acc:  99.87 / 91.9
Epoch:  81 	Train/Val Loss:  2089.62158 / 442.40326 	Train/Val Acc:  99.89 / 91.92
Epoch:  82 	Train/Val Loss:  2089.72852 / 442.38351 	Train/Val Acc:  99.85 / 91.98
Epoch:  83 	Train/Val Loss:  2089.91748 / 442.32373 	Train/Val Acc:  99.82 / 92.04
Epoch:  84 	Train/Val Loss:  2089.70581 / 442.31274 	Train/Val Acc:  99.86 / 92.06
Epoch:  85 	Train/Val Loss:  2089.82324 / 442.64203 	Train/Val Acc:  99.84 / 91.9
Epoch:  86 	Train/Val Loss:  2089.74658 / 442.31073 	Train/Val Acc:  99.86 / 91.98
Epoch:  87 	Train/Val Loss:  2089.64673 / 442.48792 	Train/Val Acc:  99.89 / 91.88
Epoch:  88 	Train/Val Loss:  2089.7041 / 442.43033 	Train/Val Acc:  99.86 / 91.91
Epoch:  89 	Train/Val Loss:  2089.71582 / 442.34863 	Train/Val Acc:  99.86 / 91.91
Epoch:  90 	Train/Val Loss:  2089.55957 / 442.58569 	Train/Val Acc:  99.86 / 91.89
Epoch:  91 	Train/Val Loss:  2089.80835 / 442.63538 	Train/Val Acc:  99.85 / 91.94
Epoch:  92 	Train/Val Loss:  2089.75195 / 442.4129 	Train/Val Acc:  99.85 / 91.99
Epoch:  93 	Train/Val Loss:  2089.85889 / 442.63763 	Train/Val Acc:  99.84 / 91.92
Epoch:  94 	Train/Val Loss:  2089.72144 / 442.41602 	Train/Val Acc:  99.87 / 91.87
Epoch:  95 	Train/Val Loss:  2089.8562 / 442.53085 	Train/Val Acc:  99.83 / 91.82
Epoch:  96 	Train/Val Loss:  2089.64136 / 442.58282 	Train/Val Acc:  99.87 / 91.91
Epoch:  97 	Train/Val Loss:  2089.8562 / 442.27054 	Train/Val Acc:  99.83 / 91.99
Epoch:  98 	Train/Val Loss:  2089.66528 / 442.34204 	Train/Val Acc:  99.87 / 91.97
Epoch:  99 	Train/Val Loss:  2089.74731 / 442.46805 	Train/Val Acc:  99.86 / 91.96
Testing on Rank 1
Testing on Rank 2
Epoch:  100 	Train/Val Loss:  2089.84326 / 442.48349 	Train/Val Acc:  99.84 / 91.93
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 1510367... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                   Train Acc ▅▂▃▆▄▆▁▅▄▇▃▄▇▄▆█▄▅▄▄▅▅▆▆▆▅▅▆▅▆█▄▅▆█▆▅▆▄▅
wandb:                                  Train Loss ▄▆▅▂▅▃█▃▄▃▄▅▂▄▁▁▄▃▅▃▄▄▂▂▂▄▃▃▃▄▁▄▂▂▁▂▃▂▄▄
wandb:                                     Val Acc ▁▁▂▄▄▆▄▄▄▂▄▁▄▆▅▄▄▄▄▅▅▄█▅▅▄▄▄▂▂▂▄▇▄▄▄▄▂▅▄
wandb:                                    Val Loss ▄▄▃▂▃▂▂▃▇▁▅▂▅▄▅▃▄▃▅▄▄▄▄▆▅▅▄▆▇▇▆▃▅█▆▇█▇▅▆
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 282282000384.0
wandb:                                     Val Acc 0.91932
wandb:                                    Val Loss 442.48349
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fast-energy-14: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/4q8mivns
wandb: Find logs at: ./wandb/run-20220110_020657-4q8mivns/logs/debug.log
wandb: 

WandB Finished
Run Complete
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-10 03:55:54.555403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-10 03:55:54.559889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run fresh-vortex-15
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/3g07r215
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220110_035552-3g07r215
wandb: Run `wandb offline` to turn off syncing.
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 2
Training on Rank 1
Training on Rank 0
Epoch:  1 	Train/Val Loss:  2089.78638 / 442.13309 	Train/Val Acc:  99.85 / 91.86
Epoch:  2 	Train/Val Loss:  2089.80786 / 442.06293 	Train/Val Acc:  99.86 / 91.89
Epoch:  3 	Train/Val Loss:  2089.79712 / 442.33069 	Train/Val Acc:  99.88 / 91.8
Epoch:  4 	Train/Val Loss:  2089.96362 / 441.99814 	Train/Val Acc:  99.84 / 92.03
Epoch:  5 	Train/Val Loss:  2090.0332 / 442.10034 	Train/Val Acc:  99.82 / 91.92
Epoch:  6 	Train/Val Loss:  2089.9563 / 442.09839 	Train/Val Acc:  99.83 / 91.9
Epoch:  7 	Train/Val Loss:  2089.8064 / 442.12637 	Train/Val Acc:  99.86 / 91.87
Epoch:  8 	Train/Val Loss:  2089.80664 / 442.10342 	Train/Val Acc:  99.84 / 91.88
Epoch:  9 	Train/Val Loss:  2089.80664 / 442.26315 	Train/Val Acc:  99.84 / 91.85
Epoch:  10 	Train/Val Loss:  2089.91113 / 442.22415 	Train/Val Acc:  99.85 / 92.05
Epoch:  11 	Train/Val Loss:  2089.86133 / 442.15448 	Train/Val Acc:  99.86 / 91.85
Epoch:  12 	Train/Val Loss:  2089.73486 / 442.24121 	Train/Val Acc:  99.88 / 91.85
Epoch:  13 	Train/Val Loss:  2089.86084 / 442.10062 	Train/Val Acc:  99.84 / 91.92
Epoch:  14 	Train/Val Loss:  2089.96948 / 442.07953 	Train/Val Acc:  99.8 / 92.08
Epoch:  15 	Train/Val Loss:  2089.98901 / 442.4924 	Train/Val Acc:  99.84 / 91.83
Epoch:  16 	Train/Val Loss:  2089.90698 / 442.01746 	Train/Val Acc:  99.82 / 91.85
Epoch:  17 	Train/Val Loss:  2089.97412 / 442.22934 	Train/Val Acc:  99.84 / 91.97
Epoch:  18 	Train/Val Loss:  2089.77808 / 442.07327 	Train/Val Acc:  99.86 / 91.85
Epoch:  19 	Train/Val Loss:  2089.89331 / 442.14392 	Train/Val Acc:  99.82 / 91.82
Epoch:  20 	Train/Val Loss:  2089.74048 / 442.11597 	Train/Val Acc:  99.87 / 91.87
Epoch:  21 	Train/Val Loss:  2089.82227 / 442.5835 	Train/Val Acc:  99.86 / 91.92
Epoch:  22 	Train/Val Loss:  2089.76196 / 442.09534 	Train/Val Acc:  99.87 / 91.93
Epoch:  23 	Train/Val Loss:  2089.8064 / 442.0386 	Train/Val Acc:  99.86 / 91.92
Epoch:  24 	Train/Val Loss:  2089.80981 / 441.87793 	Train/Val Acc:  99.85 / 91.92
Epoch:  25 	Train/Val Loss:  2089.86914 / 442.21899 	Train/Val Acc:  99.84 / 91.89
Epoch:  26 	Train/Val Loss:  2089.85498 / 442.29053 	Train/Val Acc:  99.85 / 91.92
Epoch:  27 	Train/Val Loss:  2089.88696 / 442.17203 	Train/Val Acc:  99.85 / 91.89
Epoch:  28 	Train/Val Loss:  2089.85938 / 442.39783 	Train/Val Acc:  99.84 / 91.83
Epoch:  29 	Train/Val Loss:  2089.84644 / 442.09097 	Train/Val Acc:  99.84 / 91.78
Epoch:  30 	Train/Val Loss:  2089.98755 / 442.25848 	Train/Val Acc:  99.82 / 91.99
Epoch:  31 	Train/Val Loss:  2089.72998 / 442.11157 	Train/Val Acc:  99.88 / 91.88
Epoch:  32 	Train/Val Loss:  2089.89258 / 442.08069 	Train/Val Acc:  99.84 / 92.02
Epoch:  33 	Train/Val Loss:  2089.72461 / 442.23096 	Train/Val Acc:  99.85 / 91.88
Epoch:  34 	Train/Val Loss:  2089.72388 / 442.03198 	Train/Val Acc:  99.86 / 91.99
Epoch:  35 	Train/Val Loss:  2089.91382 / 442.0011 	Train/Val Acc:  99.83 / 91.89
Epoch:  36 	Train/Val Loss:  2089.71704 / 442.22766 	Train/Val Acc:  99.87 / 91.84
Epoch:  37 	Train/Val Loss:  2089.80933 / 441.89371 	Train/Val Acc:  99.87 / 91.8
Epoch:  38 	Train/Val Loss:  2090.02148 / 442.05545 	Train/Val Acc:  99.82 / 92.0
Epoch:  39 	Train/Val Loss:  2089.81152 / 442.11313 	Train/Val Acc:  99.86 / 91.87
Epoch:  40 	Train/Val Loss:  2089.78564 / 442.15866 	Train/Val Acc:  99.86 / 91.94
Epoch:  41 	Train/Val Loss:  2089.93213 / 442.2998 	Train/Val Acc:  99.85 / 91.76
Epoch:  42 	Train/Val Loss:  2089.9541 / 442.2128 	Train/Val Acc:  99.84 / 91.92
Epoch:  43 	Train/Val Loss:  2089.92822 / 442.36267 	Train/Val Acc:  99.85 / 91.9
Epoch:  44 	Train/Val Loss:  2090.01904 / 441.98621 	Train/Val Acc:  99.82 / 91.93
Epoch:  45 	Train/Val Loss:  2089.94775 / 442.34653 	Train/Val Acc:  99.83 / 91.69
Epoch:  46 	Train/Val Loss:  2089.82568 / 442.31894 	Train/Val Acc:  99.87 / 92.0
Epoch:  47 	Train/Val Loss:  2089.78125 / 442.2536 	Train/Val Acc:  99.86 / 91.83
Epoch:  48 	Train/Val Loss:  2089.87402 / 442.35474 	Train/Val Acc:  99.85 / 91.85
Epoch:  49 	Train/Val Loss:  2089.84644 / 442.18417 	Train/Val Acc:  99.87 / 91.91
Epoch:  50 	Train/Val Loss:  2089.86987 / 442.14713 	Train/Val Acc:  99.85 / 91.84
Epoch:  51 	Train/Val Loss:  2089.83203 / 442.05469 	Train/Val Acc:  99.84 / 91.92
Epoch:  52 	Train/Val Loss:  2089.96704 / 442.07718 	Train/Val Acc:  99.85 / 91.9
Epoch:  53 	Train/Val Loss:  2089.88086 / 442.47925 	Train/Val Acc:  99.83 / 91.65
Epoch:  54 	Train/Val Loss:  2089.7876 / 442.08319 	Train/Val Acc:  99.87 / 91.95
Epoch:  55 	Train/Val Loss:  2089.95776 / 442.14468 	Train/Val Acc:  99.83 / 91.92
Epoch:  56 	Train/Val Loss:  2089.94629 / 442.13681 	Train/Val Acc:  99.85 / 91.92
Epoch:  57 	Train/Val Loss:  2089.75342 / 442.11859 	Train/Val Acc:  99.86 / 92.01
Epoch:  58 	Train/Val Loss:  2089.78564 / 442.13458 	Train/Val Acc:  99.87 / 91.93
Epoch:  59 	Train/Val Loss:  2089.83936 / 442.22995 	Train/Val Acc:  99.84 / 91.92
Epoch:  60 	Train/Val Loss:  2089.99585 / 442.18033 	Train/Val Acc:  99.83 / 91.89
Epoch:  61 	Train/Val Loss:  2089.82227 / 442.06088 	Train/Val Acc:  99.87 / 92.03
Epoch:  62 	Train/Val Loss:  2089.78931 / 442.10168 	Train/Val Acc:  99.84 / 91.92
Epoch:  63 	Train/Val Loss:  2089.92578 / 442.23849 	Train/Val Acc:  99.83 / 91.9
Epoch:  64 	Train/Val Loss:  2089.81494 / 442.19757 	Train/Val Acc:  99.86 / 91.93
Epoch:  65 	Train/Val Loss:  2090.01636 / 442.11139 	Train/Val Acc:  99.83 / 91.89
Epoch:  66 	Train/Val Loss:  2089.70337 / 442.13968 	Train/Val Acc:  99.88 / 91.81
Epoch:  67 	Train/Val Loss:  2089.75977 / 442.09378 	Train/Val Acc:  99.86 / 91.94
Epoch:  68 	Train/Val Loss:  2089.89868 / 442.241 	Train/Val Acc:  99.83 / 91.89
Epoch:  69 	Train/Val Loss:  2089.95117 / 442.41266 	Train/Val Acc:  99.84 / 91.85
Epoch:  70 	Train/Val Loss:  2089.94385 / 442.22025 	Train/Val Acc:  99.85 / 91.83
Epoch:  71 	Train/Val Loss:  2089.7832 / 442.21631 	Train/Val Acc:  99.84 / 91.82
Epoch:  72 	Train/Val Loss:  2089.76294 / 442.19 	Train/Val Acc:  99.87 / 91.77
Epoch:  73 	Train/Val Loss:  2089.96143 / 442.314 	Train/Val Acc:  99.83 / 91.83
Epoch:  74 	Train/Val Loss:  2089.73267 / 442.33499 	Train/Val Acc:  99.88 / 92.0
Epoch:  75 	Train/Val Loss:  2089.83032 / 442.30444 	Train/Val Acc:  99.86 / 91.85
Epoch:  76 	Train/Val Loss:  2089.81299 / 441.90488 	Train/Val Acc:  99.85 / 91.98
Epoch:  77 	Train/Val Loss:  2089.80713 / 442.28461 	Train/Val Acc:  99.86 / 91.9
Epoch:  78 	Train/Val Loss:  2089.93799 / 442.18842 	Train/Val Acc:  99.83 / 91.86
Epoch:  79 	Train/Val Loss:  2089.97681 / 442.14539 	Train/Val Acc:  99.83 / 91.79
Epoch:  80 	Train/Val Loss:  2089.84644 / 442.06848 	Train/Val Acc:  99.86 / 91.94
Epoch:  81 	Train/Val Loss:  2089.82324 / 442.12769 	Train/Val Acc:  99.84 / 91.96
Epoch:  82 	Train/Val Loss:  2089.74341 / 442.09039 	Train/Val Acc:  99.87 / 91.99
Epoch:  83 	Train/Val Loss:  2089.83862 / 442.06323 	Train/Val Acc:  99.87 / 91.99
Epoch:  84 	Train/Val Loss:  2089.96436 / 442.08807 	Train/Val Acc:  99.83 / 91.96
Epoch:  85 	Train/Val Loss:  2089.90381 / 442.2374 	Train/Val Acc:  99.82 / 91.9
Epoch:  86 	Train/Val Loss:  2090.06689 / 442.09842 	Train/Val Acc:  99.81 / 91.94
Epoch:  87 	Train/Val Loss:  2089.83862 / 442.17642 	Train/Val Acc:  99.86 / 91.91
Epoch:  88 	Train/Val Loss:  2089.91919 / 442.19406 	Train/Val Acc:  99.84 / 91.89
Epoch:  89 	Train/Val Loss:  2089.77368 / 441.96912 	Train/Val Acc:  99.86 / 91.92
Epoch:  90 	Train/Val Loss:  2089.66504 / 442.37299 	Train/Val Acc:  99.89 / 91.91
Epoch:  91 	Train/Val Loss:  2089.87427 / 442.30392 	Train/Val Acc:  99.88 / 91.88
Epoch:  92 	Train/Val Loss:  2089.78906 / 442.13452 	Train/Val Acc:  99.85 / 91.91
Epoch:  93 	Train/Val Loss:  2089.86816 / 442.28156 	Train/Val Acc:  99.84 / 92.02
Epoch:  94 	Train/Val Loss:  2089.84912 / 442.12537 	Train/Val Acc:  99.85 / 91.93
Epoch:  95 	Train/Val Loss:  2089.77954 / 442.35199 	Train/Val Acc:  99.85 / 91.73
Epoch:  96 	Train/Val Loss:  2089.74634 / 442.27396 	Train/Val Acc:  99.85 / 91.85
Epoch:  97 	Train/Val Loss:  2089.71533 / 442.0354 	Train/Val Acc:  99.87 / 91.94
Epoch:  98 	Train/Val Loss:  2089.95654 / 442.00281 	Train/Val Acc:  99.83 / 91.99
Epoch:  99 	Train/Val Loss:  2089.93042 / 442.11438 	Train/Val Acc:  99.86 / 91.99
Testing on Rank 2
Testing on Rank 1
Epoch:  100 	Train/Val Loss:  2089.82007 / 442.04419 	Train/Val Acc:  99.85 / 91.89
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 2191754... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁▁▁▁▁▁▁▁▄▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▃▁▂▁▁▁
wandb:                                   Train Acc ▅█▃▄▅▃▁▆▆▆▄▃█▆▆▆▅▁▆▇▃▆▅▃▇▆▆▃▆█▅▃▇▂▆▅▄▅▇▄
wandb:                                  Train Loss ▃▃▇▃▄▄▅▂▃▃▄▄▁▁▁▃▆█▄▄▄▃▆▄▃▃▂▆▂▁▃▇▂▇▄▂▃▄▁▃
wandb:                                     Val Acc ▄▃▅▅▄▆▄▄▆▆▆▂▅▇▄▄▆▆▃▅▅▆█▆▆▅▆▃▂▄▅▆▇▅▅▅█▁▇▅
wandb:                                    Val Loss ▄▅▃▃▄▃▂▃█▁▅▃▃▃▄▃▄▂▅▄▃▃▃▄▃▃▃▄▄▅▅▃▃▅▄▆▅▆▂▃
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 31386001408.0
wandb:                                     Val Acc 0.91892
wandb:                                    Val Loss 442.04419
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fresh-vortex-15: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/3g07r215
wandb: Find logs at: ./wandb/run-20220110_035552-3g07r215/logs/debug.log
wandb: 

WandB Finished
Run Complete
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-10 05:44:07.590455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-10 05:44:07.594676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run magic-dew-16
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/2j3ouayo
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220110_054405-2j3ouayo
wandb: Run `wandb offline` to turn off syncing.
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 2
Training on Rank 1
Training on Rank 0
Epoch:  1 	Train/Val Loss:  2089.80786 / 442.13666 	Train/Val Acc:  99.86 / 91.94
Epoch:  2 	Train/Val Loss:  2089.72339 / 442.09644 	Train/Val Acc:  99.86 / 91.92
Epoch:  3 	Train/Val Loss:  2089.88818 / 442.37384 	Train/Val Acc:  99.85 / 91.78
Epoch:  4 	Train/Val Loss:  2089.88916 / 442.05588 	Train/Val Acc:  99.85 / 91.95
Epoch:  5 	Train/Val Loss:  2089.77856 / 442.12439 	Train/Val Acc:  99.86 / 91.95
Epoch:  6 	Train/Val Loss:  2089.75098 / 442.06567 	Train/Val Acc:  99.87 / 91.87
Epoch:  7 	Train/Val Loss:  2089.85034 / 442.07419 	Train/Val Acc:  99.86 / 91.95
Epoch:  8 	Train/Val Loss:  2089.96143 / 442.17297 	Train/Val Acc:  99.83 / 91.98
Epoch:  9 	Train/Val Loss:  2089.80225 / 442.35034 	Train/Val Acc:  99.85 / 91.82
Epoch:  10 	Train/Val Loss:  2089.7251 / 442.19125 	Train/Val Acc:  99.87 / 91.98
Epoch:  11 	Train/Val Loss:  2089.73657 / 442.2627 	Train/Val Acc:  99.86 / 91.9
Epoch:  12 	Train/Val Loss:  2089.75122 / 442.267 	Train/Val Acc:  99.86 / 91.91
Epoch:  13 	Train/Val Loss:  2089.87573 / 442.12793 	Train/Val Acc:  99.85 / 91.97
Epoch:  14 	Train/Val Loss:  2089.94849 / 442.06668 	Train/Val Acc:  99.85 / 92.04
Epoch:  15 	Train/Val Loss:  2089.85254 / 442.33713 	Train/Val Acc:  99.85 / 91.78
Epoch:  16 	Train/Val Loss:  2090.02539 / 442.10748 	Train/Val Acc:  99.83 / 91.93
Epoch:  17 	Train/Val Loss:  2089.80688 / 442.18121 	Train/Val Acc:  99.85 / 91.98
Epoch:  18 	Train/Val Loss:  2089.94116 / 442.09222 	Train/Val Acc:  99.85 / 91.9
Epoch:  19 	Train/Val Loss:  2090.1311 / 442.20721 	Train/Val Acc:  99.79 / 91.9
Epoch:  20 	Train/Val Loss:  2089.88965 / 442.13998 	Train/Val Acc:  99.82 / 91.9
Epoch:  21 	Train/Val Loss:  2089.89893 / 442.35803 	Train/Val Acc:  99.85 / 91.93
Epoch:  22 	Train/Val Loss:  2089.90552 / 442.01389 	Train/Val Acc:  99.84 / 91.83
Epoch:  23 	Train/Val Loss:  2089.89307 / 442.16296 	Train/Val Acc:  99.84 / 91.88
Epoch:  24 	Train/Val Loss:  2089.73364 / 442.00919 	Train/Val Acc:  99.87 / 91.84
Epoch:  25 	Train/Val Loss:  2089.89453 / 442.1947 	Train/Val Acc:  99.83 / 91.88
Epoch:  26 	Train/Val Loss:  2089.8374 / 442.30789 	Train/Val Acc:  99.86 / 91.92
Epoch:  27 	Train/Val Loss:  2089.78955 / 442.11829 	Train/Val Acc:  99.85 / 91.89
Epoch:  28 	Train/Val Loss:  2089.91602 / 442.33447 	Train/Val Acc:  99.84 / 91.81
Epoch:  29 	Train/Val Loss:  2089.87378 / 442.04245 	Train/Val Acc:  99.84 / 91.76
Epoch:  30 	Train/Val Loss:  2089.98193 / 442.1763 	Train/Val Acc:  99.84 / 91.96
Epoch:  31 	Train/Val Loss:  2089.73462 / 442.0752 	Train/Val Acc:  99.86 / 91.91
Epoch:  32 	Train/Val Loss:  2089.91235 / 442.18506 	Train/Val Acc:  99.83 / 91.99
Epoch:  33 	Train/Val Loss:  2089.88525 / 442.06158 	Train/Val Acc:  99.84 / 91.85
Epoch:  34 	Train/Val Loss:  2089.83618 / 442.00854 	Train/Val Acc:  99.86 / 91.95
Epoch:  35 	Train/Val Loss:  2089.83057 / 441.95575 	Train/Val Acc:  99.84 / 91.95
Epoch:  36 	Train/Val Loss:  2089.80469 / 442.16336 	Train/Val Acc:  99.84 / 91.87
Epoch:  37 	Train/Val Loss:  2089.7959 / 441.99979 	Train/Val Acc:  99.83 / 91.79
Epoch:  38 	Train/Val Loss:  2090.04517 / 442.01019 	Train/Val Acc:  99.82 / 91.97
Epoch:  39 	Train/Val Loss:  2089.8645 / 442.18268 	Train/Val Acc:  99.84 / 91.92
Epoch:  40 	Train/Val Loss:  2089.82593 / 442.18341 	Train/Val Acc:  99.85 / 91.91
Epoch:  41 	Train/Val Loss:  2089.80249 / 442.29984 	Train/Val Acc:  99.86 / 91.86
Epoch:  42 	Train/Val Loss:  2089.81128 / 442.17157 	Train/Val Acc:  99.85 / 92.02
Epoch:  43 	Train/Val Loss:  2089.86597 / 442.27936 	Train/Val Acc:  99.84 / 91.84
Epoch:  44 	Train/Val Loss:  2089.90381 / 442.0123 	Train/Val Acc:  99.86 / 91.92
Epoch:  45 	Train/Val Loss:  2089.85474 / 442.18192 	Train/Val Acc:  99.85 / 91.75
Epoch:  46 	Train/Val Loss:  2089.83984 / 442.38834 	Train/Val Acc:  99.87 / 92.0
Epoch:  47 	Train/Val Loss:  2089.97388 / 442.18631 	Train/Val Acc:  99.87 / 91.91
Epoch:  48 	Train/Val Loss:  2089.9812 / 442.36057 	Train/Val Acc:  99.84 / 91.84
Epoch:  49 	Train/Val Loss:  2089.73071 / 442.16547 	Train/Val Acc:  99.86 / 91.95
Epoch:  50 	Train/Val Loss:  2090.03687 / 442.26416 	Train/Val Acc:  99.81 / 91.78
Epoch:  51 	Train/Val Loss:  2089.93066 / 442.04538 	Train/Val Acc:  99.83 / 91.9
Epoch:  52 	Train/Val Loss:  2089.89453 / 442.15906 	Train/Val Acc:  99.82 / 91.9
Epoch:  53 	Train/Val Loss:  2089.7937 / 442.42856 	Train/Val Acc:  99.84 / 91.74
Epoch:  54 	Train/Val Loss:  2089.84961 / 442.06519 	Train/Val Acc:  99.83 / 91.97
Epoch:  55 	Train/Val Loss:  2090.03223 / 442.21194 	Train/Val Acc:  99.82 / 91.86
Epoch:  56 	Train/Val Loss:  2089.7937 / 442.26025 	Train/Val Acc:  99.86 / 91.91
Epoch:  57 	Train/Val Loss:  2089.82349 / 442.05408 	Train/Val Acc:  99.86 / 92.01
Epoch:  58 	Train/Val Loss:  2089.86963 / 442.15338 	Train/Val Acc:  99.86 / 91.9
Epoch:  59 	Train/Val Loss:  2089.83032 / 442.26089 	Train/Val Acc:  99.85 / 91.93
Epoch:  60 	Train/Val Loss:  2090.02344 / 442.16367 	Train/Val Acc:  99.86 / 91.91
Epoch:  61 	Train/Val Loss:  2089.86206 / 442.24976 	Train/Val Acc:  99.84 / 91.92
Epoch:  62 	Train/Val Loss:  2089.65161 / 442.15292 	Train/Val Acc:  99.9 / 91.92
Epoch:  63 	Train/Val Loss:  2089.87305 / 442.08188 	Train/Val Acc:  99.84 / 91.81
Epoch:  64 	Train/Val Loss:  2089.87842 / 442.33624 	Train/Val Acc:  99.84 / 91.96
Epoch:  65 	Train/Val Loss:  2089.84937 / 442.12543 	Train/Val Acc:  99.85 / 91.87
Epoch:  66 	Train/Val Loss:  2089.95874 / 442.0033 	Train/Val Acc:  99.85 / 91.8
Epoch:  67 	Train/Val Loss:  2089.80005 / 442.06055 	Train/Val Acc:  99.87 / 91.89
Epoch:  68 	Train/Val Loss:  2089.95581 / 442.30463 	Train/Val Acc:  99.82 / 91.98
Epoch:  69 	Train/Val Loss:  2089.80664 / 442.36243 	Train/Val Acc:  99.86 / 91.92
Epoch:  70 	Train/Val Loss:  2090.04663 / 442.28604 	Train/Val Acc:  99.82 / 91.79
Epoch:  71 	Train/Val Loss:  2089.83887 / 442.30319 	Train/Val Acc:  99.87 / 91.9
Epoch:  72 	Train/Val Loss:  2089.85767 / 442.22736 	Train/Val Acc:  99.88 / 91.81
Epoch:  73 	Train/Val Loss:  2089.92798 / 442.2973 	Train/Val Acc:  99.82 / 91.82
Epoch:  74 	Train/Val Loss:  2089.78101 / 442.33752 	Train/Val Acc:  99.87 / 92.0
Epoch:  75 	Train/Val Loss:  2089.90625 / 442.25864 	Train/Val Acc:  99.85 / 91.85
Epoch:  76 	Train/Val Loss:  2089.6604 / 441.85068 	Train/Val Acc:  99.88 / 92.02
Epoch:  77 	Train/Val Loss:  2089.79395 / 442.16797 	Train/Val Acc:  99.86 / 91.88
Epoch:  78 	Train/Val Loss:  2089.93481 / 442.13327 	Train/Val Acc:  99.83 / 91.86
Epoch:  79 	Train/Val Loss:  2089.72778 / 442.07889 	Train/Val Acc:  99.88 / 91.8
Epoch:  80 	Train/Val Loss:  2089.93384 / 442.00354 	Train/Val Acc:  99.83 / 91.98
Epoch:  81 	Train/Val Loss:  2089.83472 / 442.2717 	Train/Val Acc:  99.84 / 91.91
Epoch:  82 	Train/Val Loss:  2089.85962 / 442.09787 	Train/Val Acc:  99.84 / 92.02
Epoch:  83 	Train/Val Loss:  2089.8855 / 442.11038 	Train/Val Acc:  99.84 / 91.96
Epoch:  84 	Train/Val Loss:  2089.90552 / 442.04169 	Train/Val Acc:  99.84 / 91.93
Epoch:  85 	Train/Val Loss:  2089.88916 / 442.21545 	Train/Val Acc:  99.84 / 91.86
Epoch:  86 	Train/Val Loss:  2089.93359 / 442.08487 	Train/Val Acc:  99.82 / 91.9
Epoch:  87 	Train/Val Loss:  2089.87573 / 442.14157 	Train/Val Acc:  99.83 / 91.88
Epoch:  88 	Train/Val Loss:  2089.82104 / 442.14462 	Train/Val Acc:  99.84 / 91.89
Epoch:  89 	Train/Val Loss:  2089.87573 / 442.0632 	Train/Val Acc:  99.83 / 91.85
Epoch:  90 	Train/Val Loss:  2089.76001 / 442.38492 	Train/Val Acc:  99.87 / 91.97
Epoch:  91 	Train/Val Loss:  2089.75879 / 442.38187 	Train/Val Acc:  99.85 / 91.94
Epoch:  92 	Train/Val Loss:  2089.79565 / 442.25659 	Train/Val Acc:  99.87 / 91.86
Epoch:  93 	Train/Val Loss:  2089.84912 / 442.28583 	Train/Val Acc:  99.83 / 91.99
Epoch:  94 	Train/Val Loss:  2089.76343 / 442.09573 	Train/Val Acc:  99.85 / 91.94
Epoch:  95 	Train/Val Loss:  2089.6748 / 442.2872 	Train/Val Acc:  99.88 / 91.86
Epoch:  96 	Train/Val Loss:  2089.77295 / 442.21844 	Train/Val Acc:  99.87 / 91.9
Epoch:  97 	Train/Val Loss:  2089.79688 / 442.06845 	Train/Val Acc:  99.85 / 91.98
Epoch:  98 	Train/Val Loss:  2089.66089 / 441.9754 	Train/Val Acc:  99.89 / 92.01
Epoch:  99 	Train/Val Loss:  2089.83105 / 442.09088 	Train/Val Acc:  99.86 / 91.94
Testing on Rank 1
Testing on Rank 2
Epoch:  100 	Train/Val Loss:  2089.87061 / 442.06778 	Train/Val Acc:  99.83 / 91.88
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 2873164... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁▁▁▁▁▁█▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▆▁▁▁▁▁▁▁▂▂
wandb:                                   Train Acc ▆▄▇▂▅▄▂▄▄▃▅▃▆▆▃▂▅▅▇▆▁▂▆▄▂▃▇▆█▇▆█▃▃▁▂▇▅▄▂
wandb:                                  Train Loss ▃▅▂▆▁▄█▆▅▅▄▅▁▄▃▄▃▅▄▁▆▄▃▃▄▅▃▃▄▂▃▁▄▅▄▄▃▂▃▄
wandb:                                     Val Acc ▆▂▄▇▅▇▆▅▆▃▅▁▅▆▄▅█▅▅▆▅▇█▆▅▄▅▂▂▃▄▇▆▄▅▇▇▄█▄
wandb:                                    Val Loss ▄█▃▄▆▄▃▃█▂▇▂▃▂▄▅▄▂▅▄▄▃▂▆▄▄▂▆▅▆▄▁▃▅▄█▆▆▁▃
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 18729199616.0
wandb:                                     Val Acc 0.91882
wandb:                                    Val Loss 442.06778
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced magic-dew-16: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/2j3ouayo
wandb: Find logs at: ./wandb/run-20220110_054405-2j3ouayo/logs/debug.log
wandb: 

WandB Finished
Run Complete
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-10 07:29:58.714339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-10 07:29:58.718431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run happy-pond-17
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/32i9wbn0
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220110_072957-32i9wbn0
wandb: Run `wandb offline` to turn off syncing.
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 2
Training on Rank 1
Training on Rank 0
Epoch:  1 	Train/Val Loss:  2089.84277 / 442.16672 	Train/Val Acc:  99.84 / 91.82
Epoch:  2 	Train/Val Loss:  2089.67651 / 442.06894 	Train/Val Acc:  99.87 / 92.01
Epoch:  3 	Train/Val Loss:  2089.82227 / 442.28583 	Train/Val Acc:  99.86 / 91.76
Epoch:  4 	Train/Val Loss:  2089.97681 / 442.14578 	Train/Val Acc:  99.81 / 91.97
Epoch:  5 	Train/Val Loss:  2089.82788 / 442.11609 	Train/Val Acc:  99.85 / 91.98
Epoch:  6 	Train/Val Loss:  2089.88647 / 441.97305 	Train/Val Acc:  99.84 / 91.84
Epoch:  7 	Train/Val Loss:  2089.89233 / 442.13007 	Train/Val Acc:  99.87 / 91.85
Epoch:  8 	Train/Val Loss:  2089.90454 / 442.17535 	Train/Val Acc:  99.84 / 91.86
Epoch:  9 	Train/Val Loss:  2089.97656 / 442.29333 	Train/Val Acc:  99.85 / 91.82
Epoch:  10 	Train/Val Loss:  2089.927 / 442.20135 	Train/Val Acc:  99.83 / 91.92
Epoch:  11 	Train/Val Loss:  2089.76294 / 442.16098 	Train/Val Acc:  99.86 / 91.84
Epoch:  12 	Train/Val Loss:  2089.86816 / 442.40231 	Train/Val Acc:  99.85 / 91.88
Epoch:  13 	Train/Val Loss:  2089.81396 / 442.05933 	Train/Val Acc:  99.84 / 91.96
Epoch:  14 	Train/Val Loss:  2090.07812 / 442.12592 	Train/Val Acc:  99.82 / 92.01
Epoch:  15 	Train/Val Loss:  2089.90063 / 442.29224 	Train/Val Acc:  99.85 / 91.79
Epoch:  16 	Train/Val Loss:  2089.79028 / 442.16446 	Train/Val Acc:  99.86 / 91.89
Epoch:  17 	Train/Val Loss:  2089.88428 / 442.12451 	Train/Val Acc:  99.85 / 91.91
Epoch:  18 	Train/Val Loss:  2090.00391 / 442.07599 	Train/Val Acc:  99.81 / 91.9
Epoch:  19 	Train/Val Loss:  2089.95532 / 442.20566 	Train/Val Acc:  99.85 / 91.82
Epoch:  20 	Train/Val Loss:  2089.95142 / 442.14423 	Train/Val Acc:  99.84 / 91.95
Epoch:  21 	Train/Val Loss:  2089.89014 / 442.41568 	Train/Val Acc:  99.86 / 91.94
Epoch:  22 	Train/Val Loss:  2089.88696 / 442.04434 	Train/Val Acc:  99.85 / 91.86
Epoch:  23 	Train/Val Loss:  2089.93335 / 442.21371 	Train/Val Acc:  99.82 / 91.96
Epoch:  24 	Train/Val Loss:  2089.85571 / 441.92032 	Train/Val Acc:  99.87 / 91.93
Epoch:  25 	Train/Val Loss:  2090.02734 / 442.32639 	Train/Val Acc:  99.81 / 91.79
Epoch:  26 	Train/Val Loss:  2089.9646 / 442.29053 	Train/Val Acc:  99.82 / 91.94
Epoch:  27 	Train/Val Loss:  2089.78369 / 442.16507 	Train/Val Acc:  99.86 / 91.85
Epoch:  28 	Train/Val Loss:  2089.80566 / 442.37881 	Train/Val Acc:  99.86 / 91.79
Epoch:  29 	Train/Val Loss:  2089.8811 / 442.0546 	Train/Val Acc:  99.86 / 91.81
Epoch:  30 	Train/Val Loss:  2089.82129 / 442.18896 	Train/Val Acc:  99.84 / 91.95
Epoch:  31 	Train/Val Loss:  2089.72632 / 442.19852 	Train/Val Acc:  99.87 / 91.9
Epoch:  32 	Train/Val Loss:  2089.88354 / 442.12628 	Train/Val Acc:  99.86 / 91.98
Epoch:  33 	Train/Val Loss:  2089.96704 / 442.14893 	Train/Val Acc:  99.83 / 91.88
Epoch:  34 	Train/Val Loss:  2089.78711 / 442.01834 	Train/Val Acc:  99.87 / 91.95
Epoch:  35 	Train/Val Loss:  2089.86255 / 441.9646 	Train/Val Acc:  99.85 / 91.9
Epoch:  36 	Train/Val Loss:  2089.78833 / 442.18793 	Train/Val Acc:  99.85 / 91.93
Epoch:  37 	Train/Val Loss:  2089.84497 / 441.95917 	Train/Val Acc:  99.85 / 91.86
Epoch:  38 	Train/Val Loss:  2089.90552 / 441.9549 	Train/Val Acc:  99.85 / 91.96
Epoch:  39 	Train/Val Loss:  2089.80249 / 442.073 	Train/Val Acc:  99.85 / 91.86
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: Network error resolved after 0:01:01.380528, resuming normal operation.
Epoch:  40 	Train/Val Loss:  2089.88232 / 442.10788 	Train/Val Acc:  99.83 / 91.92
Epoch:  41 	Train/Val Loss:  2089.80444 / 442.21115 	Train/Val Acc:  99.86 / 91.89
Epoch:  42 	Train/Val Loss:  2089.80566 / 442.24036 	Train/Val Acc:  99.85 / 91.95
Epoch:  43 	Train/Val Loss:  2089.90161 / 442.33694 	Train/Val Acc:  99.86 / 91.92
Epoch:  44 	Train/Val Loss:  2089.83154 / 441.97491 	Train/Val Acc:  99.85 / 91.92
Epoch:  45 	Train/Val Loss:  2089.87427 / 442.35162 	Train/Val Acc:  99.85 / 91.75
Epoch:  46 	Train/Val Loss:  2089.81494 / 442.32349 	Train/Val Acc:  99.87 / 91.96
Epoch:  47 	Train/Val Loss:  2089.75415 / 442.16312 	Train/Val Acc:  99.88 / 91.88
Epoch:  48 	Train/Val Loss:  2089.8877 / 442.43515 	Train/Val Acc:  99.86 / 91.88
Epoch:  49 	Train/Val Loss:  2089.90796 / 442.18686 	Train/Val Acc:  99.85 / 91.96
Epoch:  50 	Train/Val Loss:  2089.77173 / 442.23166 	Train/Val Acc:  99.85 / 91.78
Epoch:  51 	Train/Val Loss:  2089.91553 / 442.02948 	Train/Val Acc:  99.83 / 91.87
Epoch:  52 	Train/Val Loss:  2089.87769 / 442.10703 	Train/Val Acc:  99.85 / 91.96
Epoch:  53 	Train/Val Loss:  2089.82324 / 442.34308 	Train/Val Acc:  99.86 / 91.78
Epoch:  54 	Train/Val Loss:  2089.86206 / 442.03448 	Train/Val Acc:  99.85 / 91.91
Epoch:  55 	Train/Val Loss:  2089.76245 / 442.16388 	Train/Val Acc:  99.87 / 91.89
Epoch:  56 	Train/Val Loss:  2089.8667 / 442.19186 	Train/Val Acc:  99.86 / 91.92
Epoch:  57 	Train/Val Loss:  2089.90698 / 442.0593 	Train/Val Acc:  99.85 / 91.94
Epoch:  58 	Train/Val Loss:  2089.79688 / 442.08102 	Train/Val Acc:  99.87 / 91.96
Epoch:  59 	Train/Val Loss:  2089.85254 / 442.31387 	Train/Val Acc:  99.85 / 91.92
Epoch:  60 	Train/Val Loss:  2089.94604 / 442.10303 	Train/Val Acc:  99.83 / 91.9
Epoch:  61 	Train/Val Loss:  2089.86426 / 442.18417 	Train/Val Acc:  99.87 / 91.99
Epoch:  62 	Train/Val Loss:  2089.88501 / 442.07639 	Train/Val Acc:  99.82 / 91.9
Epoch:  63 	Train/Val Loss:  2089.75122 / 442.16721 	Train/Val Acc:  99.86 / 91.89
Epoch:  64 	Train/Val Loss:  2089.81152 / 442.34662 	Train/Val Acc:  99.85 / 91.87
Epoch:  65 	Train/Val Loss:  2089.81079 / 442.06613 	Train/Val Acc:  99.87 / 91.87
Epoch:  66 	Train/Val Loss:  2089.79272 / 442.07797 	Train/Val Acc:  99.86 / 91.87
Epoch:  67 	Train/Val Loss:  2089.81616 / 442.09354 	Train/Val Acc:  99.86 / 91.88
Epoch:  68 	Train/Val Loss:  2089.83472 / 442.35553 	Train/Val Acc:  99.86 / 91.9
Epoch:  69 	Train/Val Loss:  2089.85767 / 442.35834 	Train/Val Acc:  99.86 / 91.85
Epoch:  70 	Train/Val Loss:  2089.96484 / 442.21405 	Train/Val Acc:  99.82 / 91.89
Epoch:  71 	Train/Val Loss:  2089.79761 / 442.17557 	Train/Val Acc:  99.85 / 91.87
Epoch:  72 	Train/Val Loss:  2089.8938 / 442.2005 	Train/Val Acc:  99.83 / 91.83
Epoch:  73 	Train/Val Loss:  2089.83716 / 442.26205 	Train/Val Acc:  99.86 / 91.87
Epoch:  74 	Train/Val Loss:  2089.90601 / 442.33704 	Train/Val Acc:  99.84 / 91.93
Epoch:  75 	Train/Val Loss:  2089.85791 / 442.26495 	Train/Val Acc:  99.85 / 91.91
Epoch:  76 	Train/Val Loss:  2089.86206 / 441.80328 	Train/Val Acc:  99.86 / 91.96
Epoch:  77 	Train/Val Loss:  2089.78955 / 442.20032 	Train/Val Acc:  99.85 / 91.84
Epoch:  78 	Train/Val Loss:  2089.85669 / 442.15216 	Train/Val Acc:  99.85 / 91.93
Epoch:  79 	Train/Val Loss:  2089.7605 / 442.15646 	Train/Val Acc:  99.87 / 91.89
Epoch:  80 	Train/Val Loss:  2089.79639 / 442.0065 	Train/Val Acc:  99.84 / 91.94
Epoch:  81 	Train/Val Loss:  2089.71143 / 442.14478 	Train/Val Acc:  99.88 / 91.98
Epoch:  82 	Train/Val Loss:  2089.92773 / 442.07507 	Train/Val Acc:  99.83 / 92.06
Epoch:  83 	Train/Val Loss:  2089.71411 / 442.11688 	Train/Val Acc:  99.87 / 91.98
Epoch:  84 	Train/Val Loss:  2089.8186 / 442.10873 	Train/Val Acc:  99.86 / 92.01
Epoch:  85 	Train/Val Loss:  2090.01147 / 442.19577 	Train/Val Acc:  99.84 / 91.95
Epoch:  86 	Train/Val Loss:  2089.88135 / 442.00079 	Train/Val Acc:  99.85 / 91.85
Epoch:  87 	Train/Val Loss:  2089.8916 / 442.07898 	Train/Val Acc:  99.85 / 91.8
Epoch:  88 	Train/Val Loss:  2089.85156 / 442.21866 	Train/Val Acc:  99.84 / 91.85
Epoch:  89 	Train/Val Loss:  2089.87305 / 442.12616 	Train/Val Acc:  99.85 / 91.91
Epoch:  90 	Train/Val Loss:  2089.63501 / 442.31815 	Train/Val Acc:  99.87 / 91.96
Epoch:  91 	Train/Val Loss:  2089.93311 / 442.43625 	Train/Val Acc:  99.85 / 91.91
Epoch:  92 	Train/Val Loss:  2089.85889 / 442.23581 	Train/Val Acc:  99.86 / 91.89
Epoch:  93 	Train/Val Loss:  2089.93579 / 442.28683 	Train/Val Acc:  99.84 / 91.91
Epoch:  94 	Train/Val Loss:  2090.1416 / 442.25766 	Train/Val Acc:  99.79 / 91.94
Epoch:  95 	Train/Val Loss:  2089.90381 / 442.23282 	Train/Val Acc:  99.83 / 91.78
Epoch:  96 	Train/Val Loss:  2089.88696 / 442.28461 	Train/Val Acc:  99.83 / 91.94
Epoch:  97 	Train/Val Loss:  2089.83911 / 442.05899 	Train/Val Acc:  99.86 / 92.05
Epoch:  98 	Train/Val Loss:  2089.70068 / 441.94531 	Train/Val Acc:  99.88 / 92.02
Epoch:  99 	Train/Val Loss:  2089.84741 / 442.11414 	Train/Val Acc:  99.83 / 91.93
Testing on Rank 1
Testing on Rank 2
Epoch:  100 	Train/Val Loss:  2089.81689 / 441.98221 	Train/Val Acc:  99.85 / 91.97
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 3554174... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁
wandb:                                   Train Acc ▆▇▆▆▇▆▇▃▇▄▃▇██▆▆▇▆█▆▄▆▇▆█▆▇▇▅▆▆▇▄▇▆▆▇▁▇▆
wandb:                                  Train Loss ▃▃▄▄▂▂▂▆▄▄▅▂▁▂▂▂▂▃▂▄▄▃▃▃▃▂▃▃▄▄▂▂▄▃▄▃▃█▃▃
wandb:                                     Val Acc ▃▁▃▄▃▆▅▅▆▆▆▂▅▆▆▄▆▅▄▆▆▅▆▅▅▄▄▅▃▅▃▆▇▆▃▆▅▂█▇
wandb:                                    Val Loss ▄▆▂▅▄▃▄▃█▁▆▃▅▂▅▃▆▂▄▅▄▃▃▇▃▃▃▅▅▆▅▂▄▅▅▇▆▅▁▂
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 131530915840.0
wandb:                                     Val Acc 0.91972
wandb:                                    Val Loss 441.98221
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced happy-pond-17: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/32i9wbn0
wandb: Find logs at: ./wandb/run-20220110_072957-32i9wbn0/logs/debug.log
wandb: 

WandB Finished
Run Complete
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2022-01-10 09:15:40.306410: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2022-01-10 09:15:40.310620: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.12.3
wandb: Syncing run cool-brook-18
wandb:  View project at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10
wandb:  View run at https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/106s2pa0
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20220110_091538-106s2pa0
wandb: Run `wandb offline` to turn off syncing.
Augmenting Training Data on Rank  2
Files already downloaded and verified
Files already downloaded and verified
Augmenting Training Data on Rank  1
Files already downloaded and verified
Files already downloaded and verified

Augmenting Training Data on Rank  0
Files already downloaded and verified
Files already downloaded and verified
Training on Rank 2
Training on Rank 0
Training on Rank 1
Epoch:  1 	Train/Val Loss:  2089.8125 / 442.14783 	Train/Val Acc:  99.84 / 91.87
Epoch:  2 	Train/Val Loss:  2089.91504 / 442.14417 	Train/Val Acc:  99.86 / 92.05
Epoch:  3 	Train/Val Loss:  2089.854 / 442.39407 	Train/Val Acc:  99.84 / 91.82
Epoch:  4 	Train/Val Loss:  2089.84546 / 442.16776 	Train/Val Acc:  99.85 / 92.01
Epoch:  5 	Train/Val Loss:  2089.7749 / 442.20435 	Train/Val Acc:  99.84 / 92.03
Epoch:  6 	Train/Val Loss:  2089.8252 / 442.12134 	Train/Val Acc:  99.84 / 91.84
Epoch:  7 	Train/Val Loss:  2089.85669 / 442.12573 	Train/Val Acc:  99.86 / 91.89
Epoch:  8 	Train/Val Loss:  2089.86401 / 442.10693 	Train/Val Acc:  99.85 / 91.96
Epoch:  9 	Train/Val Loss:  2089.8584 / 442.12894 	Train/Val Acc:  99.85 / 91.94
Epoch:  10 	Train/Val Loss:  2089.83862 / 442.20236 	Train/Val Acc:  99.86 / 91.94
Epoch:  11 	Train/Val Loss:  2089.82593 / 442.21506 	Train/Val Acc:  99.86 / 91.84
Epoch:  12 	Train/Val Loss:  2089.99072 / 442.35657 	Train/Val Acc:  99.82 / 91.75
Epoch:  13 	Train/Val Loss:  2089.927 / 442.06277 	Train/Val Acc:  99.82 / 92.0
Epoch:  14 	Train/Val Loss:  2089.91797 / 442.14014 	Train/Val Acc:  99.84 / 92.05
Epoch:  15 	Train/Val Loss:  2089.80835 / 442.38843 	Train/Val Acc:  99.87 / 91.8
Epoch:  16 	Train/Val Loss:  2089.979 / 442.14597 	Train/Val Acc:  99.81 / 91.9
Epoch:  17 	Train/Val Loss:  2089.87964 / 442.21277 	Train/Val Acc:  99.84 / 91.95
Epoch:  18 	Train/Val Loss:  2089.84277 / 441.99915 	Train/Val Acc:  99.86 / 91.93
Epoch:  19 	Train/Val Loss:  2089.96216 / 442.15021 	Train/Val Acc:  99.83 / 91.89
Epoch:  20 	Train/Val Loss:  2089.80737 / 442.09598 	Train/Val Acc:  99.86 / 91.93
Epoch:  21 	Train/Val Loss:  2089.87085 / 442.38757 	Train/Val Acc:  99.81 / 91.89
Epoch:  22 	Train/Val Loss:  2089.82324 / 442.09653 	Train/Val Acc:  99.86 / 91.83
Epoch:  23 	Train/Val Loss:  2089.83081 / 442.20721 	Train/Val Acc:  99.84 / 91.83
Epoch:  24 	Train/Val Loss:  2089.89844 / 442.05548 	Train/Val Acc:  99.85 / 91.93
Epoch:  25 	Train/Val Loss:  2089.9292 / 442.30295 	Train/Val Acc:  99.84 / 91.81
Epoch:  26 	Train/Val Loss:  2090.04956 / 442.37482 	Train/Val Acc:  99.82 / 91.86
Epoch:  27 	Train/Val Loss:  2089.7959 / 442.11618 	Train/Val Acc:  99.87 / 91.81
Epoch:  28 	Train/Val Loss:  2089.96899 / 442.35834 	Train/Val Acc:  99.83 / 91.84
Epoch:  29 	Train/Val Loss:  2089.85303 / 442.06378 	Train/Val Acc:  99.87 / 91.73
Epoch:  30 	Train/Val Loss:  2089.95337 / 442.23965 	Train/Val Acc:  99.81 / 92.0
Epoch:  31 	Train/Val Loss:  2089.88623 / 442.14343 	Train/Val Acc:  99.82 / 91.98
Epoch:  32 	Train/Val Loss:  2089.81641 / 442.28925 	Train/Val Acc:  99.85 / 91.85
Epoch:  33 	Train/Val Loss:  2089.88867 / 442.0882 	Train/Val Acc:  99.85 / 91.84
Epoch:  34 	Train/Val Loss:  2089.74536 / 442.005 	Train/Val Acc:  99.86 / 91.95
Epoch:  35 	Train/Val Loss:  2090.00513 / 442.01505 	Train/Val Acc:  99.81 / 91.95
Epoch:  36 	Train/Val Loss:  2089.87817 / 442.29599 	Train/Val Acc:  99.85 / 91.92
Epoch:  37 	Train/Val Loss:  2089.96167 / 442.03751 	Train/Val Acc:  99.83 / 91.79
Epoch:  38 	Train/Val Loss:  2090.04932 / 441.98831 	Train/Val Acc:  99.84 / 91.94
Epoch:  39 	Train/Val Loss:  2089.71826 / 442.17056 	Train/Val Acc:  99.89 / 91.86
Epoch:  40 	Train/Val Loss:  2090.08398 / 442.22055 	Train/Val Acc:  99.8 / 91.91
Epoch:  41 	Train/Val Loss:  2089.81128 / 442.36642 	Train/Val Acc:  99.85 / 91.74
Epoch:  42 	Train/Val Loss:  2089.89551 / 442.15356 	Train/Val Acc:  99.85 / 91.94
Epoch:  43 	Train/Val Loss:  2089.9021 / 442.36734 	Train/Val Acc:  99.84 / 91.97
Epoch:  44 	Train/Val Loss:  2089.86475 / 442.08633 	Train/Val Acc:  99.86 / 91.94
Epoch:  45 	Train/Val Loss:  2089.74414 / 442.31113 	Train/Val Acc:  99.85 / 91.63
Epoch:  46 	Train/Val Loss:  2089.79175 / 442.31683 	Train/Val Acc:  99.85 / 92.02
Epoch:  47 	Train/Val Loss:  2089.84131 / 442.20737 	Train/Val Acc:  99.84 / 91.93
Epoch:  48 	Train/Val Loss:  2089.88843 / 442.37723 	Train/Val Acc:  99.83 / 91.81
Epoch:  49 	Train/Val Loss:  2089.86963 / 442.22275 	Train/Val Acc:  99.84 / 91.93
Epoch:  50 	Train/Val Loss:  2089.80981 / 442.21457 	Train/Val Acc:  99.85 / 91.82
Epoch:  51 	Train/Val Loss:  2089.79468 / 441.9599 	Train/Val Acc:  99.85 / 91.96
Epoch:  52 	Train/Val Loss:  2089.84497 / 442.0347 	Train/Val Acc:  99.85 / 91.93
Epoch:  53 	Train/Val Loss:  2089.80396 / 442.45596 	Train/Val Acc:  99.84 / 91.65
Epoch:  54 	Train/Val Loss:  2089.91406 / 442.0141 	Train/Val Acc:  99.84 / 91.98
Epoch:  55 	Train/Val Loss:  2089.88257 / 442.18277 	Train/Val Acc:  99.85 / 91.91
Epoch:  56 	Train/Val Loss:  2089.8894 / 442.23267 	Train/Val Acc:  99.84 / 91.96
Epoch:  57 	Train/Val Loss:  2089.76758 / 442.0531 	Train/Val Acc:  99.88 / 91.94
Epoch:  58 	Train/Val Loss:  2089.82153 / 442.04468 	Train/Val Acc:  99.85 / 91.92
Epoch:  59 	Train/Val Loss:  2089.97729 / 442.28149 	Train/Val Acc:  99.79 / 91.96
Epoch:  60 	Train/Val Loss:  2089.99634 / 442.18216 	Train/Val Acc:  99.82 / 91.97
Epoch:  61 	Train/Val Loss:  2089.77954 / 442.20685 	Train/Val Acc:  99.87 / 91.96
Epoch:  62 	Train/Val Loss:  2089.72778 / 442.13968 	Train/Val Acc:  99.87 / 91.93
Epoch:  63 	Train/Val Loss:  2089.81543 / 442.16727 	Train/Val Acc:  99.85 / 91.82
Epoch:  64 	Train/Val Loss:  2089.79126 / 442.23364 	Train/Val Acc:  99.89 / 91.93
Epoch:  65 	Train/Val Loss:  2089.78271 / 442.21747 	Train/Val Acc:  99.86 / 91.91
Epoch:  66 	Train/Val Loss:  2089.83447 / 442.12268 	Train/Val Acc:  99.85 / 91.83
Epoch:  67 	Train/Val Loss:  2089.78223 / 442.06708 	Train/Val Acc:  99.86 / 91.95
Epoch:  68 	Train/Val Loss:  2089.89746 / 442.32272 	Train/Val Acc:  99.85 / 91.95
Epoch:  69 	Train/Val Loss:  2090.01221 / 442.39676 	Train/Val Acc:  99.82 / 91.85
Epoch:  70 	Train/Val Loss:  2089.76343 / 442.15387 	Train/Val Acc:  99.86 / 91.86
Epoch:  71 	Train/Val Loss:  2089.85962 / 442.34769 	Train/Val Acc:  99.85 / 91.9
Epoch:  72 	Train/Val Loss:  2089.93506 / 442.12024 	Train/Val Acc:  99.84 / 91.77
Epoch:  73 	Train/Val Loss:  2089.92188 / 442.30508 	Train/Val Acc:  99.82 / 91.81
Epoch:  74 	Train/Val Loss:  2089.74658 / 442.19995 	Train/Val Acc:  99.88 / 91.99
Epoch:  75 	Train/Val Loss:  2089.82642 / 442.35544 	Train/Val Acc:  99.87 / 91.83
Epoch:  76 	Train/Val Loss:  2089.88037 / 441.8067 	Train/Val Acc:  99.83 / 91.95
Epoch:  77 	Train/Val Loss:  2089.70117 / 442.16507 	Train/Val Acc:  99.88 / 91.87
Epoch:  78 	Train/Val Loss:  2089.97412 / 442.16937 	Train/Val Acc:  99.81 / 91.98
Epoch:  79 	Train/Val Loss:  2089.78247 / 442.27844 	Train/Val Acc:  99.85 / 91.83
Epoch:  80 	Train/Val Loss:  2089.9021 / 442.02115 	Train/Val Acc:  99.84 / 91.94
Epoch:  81 	Train/Val Loss:  2089.9082 / 442.22806 	Train/Val Acc:  99.84 / 91.89
Epoch:  82 	Train/Val Loss:  2089.80762 / 442.06354 	Train/Val Acc:  99.84 / 92.03
Epoch:  83 	Train/Val Loss:  2089.96436 / 442.15656 	Train/Val Acc:  99.82 / 91.9
Epoch:  84 	Train/Val Loss:  2089.82593 / 442.0419 	Train/Val Acc:  99.84 / 91.97
Epoch:  85 	Train/Val Loss:  2089.78711 / 442.34854 	Train/Val Acc:  99.86 / 91.83
Epoch:  86 	Train/Val Loss:  2089.94995 / 442.14761 	Train/Val Acc:  99.83 / 91.99
Epoch:  87 	Train/Val Loss:  2089.79443 / 442.21857 	Train/Val Acc:  99.86 / 91.88
Epoch:  88 	Train/Val Loss:  2089.82251 / 442.20825 	Train/Val Acc:  99.85 / 91.9
Epoch:  89 	Train/Val Loss:  2089.74023 / 442.09488 	Train/Val Acc:  99.86 / 91.91
Epoch:  90 	Train/Val Loss:  2089.62402 / 442.3201 	Train/Val Acc:  99.89 / 91.99
Epoch:  91 	Train/Val Loss:  2089.81909 / 442.37033 	Train/Val Acc:  99.87 / 91.89
Epoch:  92 	Train/Val Loss:  2089.83203 / 442.21616 	Train/Val Acc:  99.83 / 91.9
Epoch:  93 	Train/Val Loss:  2089.91504 / 442.25659 	Train/Val Acc:  99.84 / 91.92
Epoch:  94 	Train/Val Loss:  2089.98584 / 442.12991 	Train/Val Acc:  99.84 / 91.87
Epoch:  95 	Train/Val Loss:  2089.74292 / 442.23972 	Train/Val Acc:  99.87 / 91.82
Epoch:  96 	Train/Val Loss:  2089.95996 / 442.33014 	Train/Val Acc:  99.82 / 91.93
Epoch:  97 	Train/Val Loss:  2089.77637 / 442.08978 	Train/Val Acc:  99.87 / 91.98
Epoch:  98 	Train/Val Loss:  2089.85327 / 441.99329 	Train/Val Acc:  99.85 / 91.99
Epoch:  99 	Train/Val Loss:  2090.04907 / 442.17166 	Train/Val Acc:  99.83 / 91.9
Testing on Rank 1
Testing on Rank 2
Epoch:  100 	Train/Val Loss:  2090.00781 / 442.0567 	Train/Val Acc:  99.83 / 91.83
Testing on Rank 0
Evaluating Results 2
Val Gathered 2
Adv Gathered 2
Evaluating Results 1
Val Gathered 1
Adv Gathered 1
Evaluating Results 0
Val Gathered 0
Adv Gathered 0
Logging
Log
Saving Model
Model Saved
wandb: Waiting for W&B process to finish, PID 41373... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:                                       Epoch ▁
wandb:                           Label Smooth Loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                   Train Acc ▅▄▄▅▆▃▂▆▃▄▃▄▃▆▅█▆▆▅▅▅▅▅▁▆█▆▃▅█▇▆▅▅▆▆▄▅▇▄
wandb:                                  Train Loss ▃▄▃▄▄▆▇▄▄▄█▆▅▂▅▁▃▄▃▄▃▅▅▇▃▃▃▇▆▂▁▃▃▄▃▂▄▇▃▇
wandb:                                     Val Acc ▅▃▄▇▄█▅▆▅▆▄▁▇▇▆▄▆▆▆▆▆▇▆▇▆▆▇▄▂▄▅▆▅▄▅█▆▃█▄
wandb:                                    Val Loss ▄█▃▃▅▂▄▁█▂█▂▄▁▆▄▄▃▅▅▂▁▂▆▄▅▂▄▃▇▄▁▄▇▅▇▆▅▁▂
wandb:   current_label_smooth_regularization_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                       epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                    sched lr ▁▁▂▂▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 100
wandb:                           Label Smooth Loss 59981819904.0
wandb:                                     Val Acc 0.91832
wandb:                                    Val Loss 442.0567
wandb:   current_label_smooth_regularization_coeff 0.002
wandb:                                       epoch 100
wandb:                                    sched lr 0.0
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced cool-brook-18: https://wandb.ai/naddeok/DDP%20LSR%20CIFAR10/runs/106s2pa0
wandb: Find logs at: ./wandb/run-20220110_091538-106s2pa0/logs/debug.log
wandb: 

WandB Finished
Run Complete
Traceback (most recent call last):
  File "ddp_model_trainer.py", line 720, in <module>
    for value in sweep_config[key]:
  File "ddp_model_trainer.py", line 586, in run_ddp
    
  File "/home/naddeok5/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/naddeok5/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/home/naddeok5/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/home/naddeok5/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/home/naddeok5/FIM/ddp_model_trainer.py", line 149, in train
    run = setup(rank, world_size, config, project_name)
  File "/home/naddeok5/FIM/ddp_model_trainer.py", line 30, in setup
    os.environ['MASTER_PORT'] = int(random.randrange(12340, 12370))
  File "/usr/lib/python3.8/os.py", line 680, in __setitem__
    value = self.encodevalue(value)
  File "/usr/lib/python3.8/os.py", line 750, in encode
    raise TypeError("str expected, not %s" % type(value).__name__)
TypeError: str expected, not int

[lambda01][[6827,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(50) failed: Connection reset by peer (104)
[lambda01][[6827,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(51) failed: Connection reset by peer (104)
[lambda01][[6827,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(52) failed: Connection reset by peer (104)
[lambda01][[6827,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(58) failed: Connection reset by peer (104)
[lambda01][[6827,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(32) failed: Connection reset by peer (104)
