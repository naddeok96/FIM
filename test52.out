Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(wandb_model_trainer.py:3603438): Gdk-CRITICAL **: 05:59:51.814: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
wandb: Agent Starting Run: d7ax7xj2 with config:
wandb: 	batch_size: 4
wandb: 	criterion: cross_entropy
wandb: 	epochs: 300
wandb: 	learning_rate: 0.03427390893709629
wandb: 	model_name: cifar10_mobilenetv2_x1_4
wandb: 	momentum: 0.9
wandb: 	optimizer: nesterov
wandb: 	pretrained: False
wandb: 	scheduler: Cosine Annealing
wandb: 	transformation: models/pretrained/U_w_means_0-005174736492335796_n0-0014449692098423839_n0-0010137659264728427_and_stds_1-130435824394226_1-128873586654663_1-1922636032104492_.pt
wandb: 	use_SAM: True
wandb: 	weight_decay: 1e-05
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
Files already downloaded and verified
Files already downloaded and verified
CIFAR10 is Loaded
Create sweep with ID: flyag8te
Sweep URL: https://wandb.ai/naddeok/CIFAR10/sweeps/flyag8te
wandb: wandb version 0.10.31 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-06-01 05:59:56.942507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-06-01 05:59:56.945221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
wandb: Tracking run with wandb version 0.10.30
wandb: Syncing run smart-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/naddeok/CIFAR10
wandb: üßπ View sweep at https://wandb.ai/naddeok/CIFAR10/sweeps/flyag8te
wandb: üöÄ View run at https://wandb.ai/naddeok/CIFAR10/runs/d7ax7xj2
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210601_055955-d7ax7xj2
wandb: Run `wandb offline` to turn off syncing.

signal only works in main thread
Using cache found in /home/naddeok5/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master
Epoch:  1 	Train Loss:  0.20709562650092528 	Val Loss:  0.003387243777513504
Epoch:  3 	Train Loss:  0.16874487071216107 	Val Loss:  0.0033408335208892823
Epoch:  5 	Train Loss:  0.15265250453578308 	Val Loss:  0.0031997435867786406
Epoch:  7 	Train Loss:  0.13992949474310504 	Val Loss:  0.003237903618812561
Epoch:  9 	Train Loss:  0.131328790341313 	Val Loss:  0.0033890105485916136
Epoch:  11 	Train Loss:  0.12369472951845033 	Val Loss:  0.003244120538234711
Epoch:  13 	Train Loss:  0.11717412410465301 	Val Loss:  0.0032765562891960143
