Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(wandb_model_trainer.py:1391335): Gdk-CRITICAL **: 07:02:23.260: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
wandb: Agent Starting Run: 0lm370rh with config:
wandb: 	batch_size: 256
wandb: 	criterion: cross_entropy
wandb: 	epochs: 100
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0.8
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.001
wandb: Currently logged in as: naddeok (use `wandb login --relogin` to force relogin)
Create sweep with ID: jy0kyowp
Sweep URL: https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 07:02:28.605787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 07:02:28.610991: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run easy-sweep-1
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/0lm370rh
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_070226-0lm370rh
wandb: Run `wandb offline` to turn off syncing.
Epoch:  1 	Train Loss:  0.008975791482925415 	Val Loss:  0.009041426944732665
Epoch:  11 	Train Loss:  0.00805588263988495 	Val Loss:  0.00819430890083313
Epoch:  21 	Train Loss:  0.0077736861610412595 	Val Loss:  0.007941666293144226
Epoch:  31 	Train Loss:  0.007628341069221497 	Val Loss:  0.007823321211338044
Epoch:  41 	Train Loss:  0.007527721700668335 	Val Loss:  0.007750144755840301
Epoch:  51 	Train Loss:  0.007435269310474396 	Val Loss:  0.007650514352321625
Epoch:  61 	Train Loss:  0.007328961293697357 	Val Loss:  0.007560480499267578
Epoch:  71 	Train Loss:  0.007254668972492218 	Val Loss:  0.007542056202888489
Epoch:  81 	Train Loss:  0.007202030494213104 	Val Loss:  0.007483668720722199
Epoch:  91 	Train Loss:  0.007155984945297241 	Val Loss:  0.007461315608024597
wandb: Waiting for W&B process to finish, PID 1391548
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_070226-0lm370rh/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_070226-0lm370rh/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 0.00713
wandb:    Train Acc 0.55267
wandb:      Val MSE 0.00746
wandb:      Val Acc 0.6013
wandb:        _step 10
wandb:     _runtime 243
wandb:   _timestamp 1619521589
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▅▃▃▃▂▂▁▁▁▁
wandb:    Train Acc ▁▄▅▆▆▇▇▇███
wandb:      Val MSE █▄▃▃▂▂▁▁▁▁▁
wandb:      Val Acc ▁▅▆▆▇▇█████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced easy-sweep-1: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/0lm370rh
wandb: Agent Starting Run: ssfhhzx4 with config:
wandb: 	batch_size: 256
wandb: 	criterion: cross_entropy
wandb: 	epochs: 1000
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 512
wandb: 	num_nodes_fc_layer: 256
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.05

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 07:06:35.696345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 07:06:35.703319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run giddy-sweep-2
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/ssfhhzx4
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_070633-ssfhhzx4
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.009023073554039002 	Val Loss:  0.009209502363204955
Epoch:  101 	Train Loss:  0.00902613853931427 	Val Loss:  0.00921034038066864
Epoch:  201 	Train Loss:  0.009026138586997986 	Val Loss:  0.009210341119766235
Epoch:  301 	Train Loss:  0.009026138062477112 	Val Loss:  0.00921034026145935
Epoch:  401 	Train Loss:  0.009026138772964478 	Val Loss:  0.00921034128665924
Epoch:  501 	Train Loss:  0.009026139307022094 	Val Loss:  0.009210338807106018
Epoch:  601 	Train Loss:  0.00902613869190216 	Val Loss:  0.00921034026145935
Epoch:  701 	Train Loss:  0.009026138606071472 	Val Loss:  0.009210339546203613
Epoch:  801 	Train Loss:  0.009026138882637024 	Val Loss:  0.009210339021682739
Epoch:  901 	Train Loss:  0.009026138172149659 	Val Loss:  0.009210338091850281
wandb: Waiting for W&B process to finish, PID 1397367
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_070633-ssfhhzx4/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_070633-ssfhhzx4/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 999
wandb:    Train MSE 0.00903
wandb:    Train Acc 0.09776
wandb:      Val MSE 0.00921
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 2346
wandb:   _timestamp 1619523939
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE ▁██████████
wandb:    Train Acc █▁▁▁▁▁▁▁▁▁▁
wandb:      Val MSE ▁██████████
wandb:      Val Acc █▁▁▁▁▁▁▁▁▁▁
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced giddy-sweep-2: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/ssfhhzx4
wandb: Agent Starting Run: d9yy0xwn with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 100
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 07:45:45.548680: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 07:45:45.555125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run brisk-sweep-3
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/d9yy0xwn
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_074543-d9yy0xwn
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0014088485756516456 	Val Loss:  0.00036025825068354604
Epoch:  11 	Train Loss:  0.0014058150523900985 	Val Loss:  0.0003594852738082409
Epoch:  21 	Train Loss:  0.0014034724612534046 	Val Loss:  0.00035887393355369567
Epoch:  31 	Train Loss:  0.0014013728991150857 	Val Loss:  0.0003583271861076355
Epoch:  41 	Train Loss:  0.0013994385080039501 	Val Loss:  0.00035781851634383204
Epoch:  51 	Train Loss:  0.0013976477341353893 	Val Loss:  0.0003573460787534714
Epoch:  61 	Train Loss:  0.0013960072109103203 	Val Loss:  0.00035691001042723654
Epoch:  71 	Train Loss:  0.0013945201125741004 	Val Loss:  0.0003565103270113468
Epoch:  81 	Train Loss:  0.0013931413747370243 	Val Loss:  0.00035614486709237096
Epoch:  91 	Train Loss:  0.0013918981260061265 	Val Loss:  0.00035581050887703895
wandb: Waiting for W&B process to finish, PID 1445906
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_074543-d9yy0xwn/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_074543-d9yy0xwn/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 0.00139
wandb:    Train Acc 0.15036
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1573
wandb:        _step 10
wandb:     _runtime 632
wandb:   _timestamp 1619524575
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▇▆▅▄▄▃▂▂▁▁
wandb:    Train Acc ▁▂▄▅▆▇▇▇███
wandb:      Val MSE █▇▆▅▄▄▃▂▂▁▁
wandb:      Val Acc ▁▃▆▇▇██████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced brisk-sweep-3: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/d9yy0xwn
wandb: Agent Starting Run: 26qgymqg with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 128
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 128
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 07:56:21.465916: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 07:56:21.473178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run stilted-sweep-4
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/26qgymqg
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_075619-26qgymqg
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0013555855599045753 	Val Loss:  0.0003445860810577869
Epoch:  501 	Train Loss:  0.0013496208491921425 	Val Loss:  0.00034426127523183825
Epoch:  1001 	Train Loss:  0.0013498379045724868 	Val Loss:  0.000344601646065712
Epoch:  1501 	Train Loss:  0.0013496736048161984 	Val Loss:  0.00034441902041435244
Epoch:  2001 	Train Loss:  0.0013497668689489365 	Val Loss:  0.00034412078112363816
Epoch:  2501 	Train Loss:  0.0013499682633578778 	Val Loss:  0.0003442271515727043
Epoch:  3001 	Train Loss:  0.0013499156683683395 	Val Loss:  0.00034420112371444703
Epoch:  3501 	Train Loss:  0.0013497672274708748 	Val Loss:  0.00034482212439179423
Epoch:  4001 	Train Loss:  0.0013498818866908551 	Val Loss:  0.0003439830020070076
Epoch:  4501 	Train Loss:  0.0013498959141969682 	Val Loss:  0.00034418067410588263
wandb: Waiting for W&B process to finish, PID 1455225
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_075619-26qgymqg/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_075619-26qgymqg/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.00135
wandb:    Train Acc 0.17936
wandb:      Val MSE 0.00034
wandb:      Val Acc 0.1837
wandb:        _step 10
wandb:     _runtime 37071
wandb:   _timestamp 1619561650
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc █▁▁▁▁▁▁▁▁▁▁
wandb:      Val MSE ▆▃▆▅▂▃▃█▁▃▂
wandb:      Val Acc █▁█▅▆▇▇▇▁▄█
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▄▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▄▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced stilted-sweep-4: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/26qgymqg
wandb: Agent Starting Run: konmv9ec with config:
wandb: 	batch_size: 64
wandb: 	criterion: cross_entropy
wandb: 	epochs: 100
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 18:14:16.832626: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 18:14:16.837148: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run astral-sweep-5
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/konmv9ec
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_181415-konmv9ec
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.035779504470825195 	Val Loss:  0.00904957342147827
Epoch:  11 	Train Loss:  0.03198832260608673 	Val Loss:  0.008153790879249573
Epoch:  21 	Train Loss:  0.030295771961212158 	Val Loss:  0.007773575341701508
Epoch:  31 	Train Loss:  0.02904135460138321 	Val Loss:  0.007485558664798737
Epoch:  41 	Train Loss:  0.028177700564861297 	Val Loss:  0.007423818027973175
Epoch:  51 	Train Loss:  0.027581760475635528 	Val Loss:  0.007298225009441376
Epoch:  61 	Train Loss:  0.027129448599815368 	Val Loss:  0.007274204444885254
Epoch:  71 	Train Loss:  0.026727008249759675 	Val Loss:  0.007228536677360535
Epoch:  81 	Train Loss:  0.02638365449666977 	Val Loss:  0.007203654849529267
Epoch:  91 	Train Loss:  0.026087019979953767 	Val Loss:  0.007119870710372925
wandb: Waiting for W&B process to finish, PID 2055976
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_181415-konmv9ec/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_181415-konmv9ec/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 0.02582
wandb:    Train Acc 0.66047
wandb:      Val MSE 0.00711
wandb:      Val Acc 0.6865
wandb:        _step 10
wandb:     _runtime 521
wandb:   _timestamp 1619562176
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▅▄▃▃▂▂▂▁▁▁
wandb:    Train Acc ▁▃▄▅▆▆▇▇▇██
wandb:      Val MSE █▅▃▂▂▂▂▁▁▁▁
wandb:      Val Acc ▁▄▆▇▇▇▇████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced astral-sweep-5: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/konmv9ec
wandb: Agent Starting Run: hbpyof9i with config:
wandb: 	batch_size: 124
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 512
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.001

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 18:23:02.371661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 18:23:02.379399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run decent-sweep-6
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/hbpyof9i
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_182300-hbpyof9i
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0006963942392170429 	Val Loss:  0.0003340563483536243
Epoch:  501 	Train Loss:  0.0003598232662677765 	Val Loss:  0.00019965120330452918
Epoch:  1001 	Train Loss:  0.00035715216994285586 	Val Loss:  0.00018599146641790868
Epoch:  1501 	Train Loss:  0.00035634020283818247 	Val Loss:  0.00018867287933826447
Epoch:  2001 	Train Loss:  0.00035563659869134427 	Val Loss:  0.00020289915688335896
Epoch:  2501 	Train Loss:  0.00035611938662827015 	Val Loss:  0.0001893233574926853
Epoch:  3001 	Train Loss:  0.0003563974814862013 	Val Loss:  0.0001848565522581339
Epoch:  3501 	Train Loss:  0.00035600990697741506 	Val Loss:  0.00019960259310901164
Epoch:  4001 	Train Loss:  0.00035564148761332035 	Val Loss:  0.000190118408203125
Epoch:  4501 	Train Loss:  0.00035480566561222075 	Val Loss:  0.00018670207522809506
wandb: Waiting for W&B process to finish, PID 2146086
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_182300-hbpyof9i/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_182300-hbpyof9i/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.00035
wandb:    Train Acc 0.68992
wandb:      Val MSE 0.00019
wandb:      Val Acc 0.6692
wandb:        _step 10
wandb:     _runtime 16225
wandb:   _timestamp 1619578405
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁██████████
wandb:      Val MSE █▂▁▁▂▁▁▂▁▁▁
wandb:      Val Acc ▁▇██▇██▇███
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced decent-sweep-6: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/hbpyof9i
wandb: Agent Starting Run: 46cpc1mb with config:
wandb: 	batch_size: 124
wandb: 	criterion: mse
wandb: 	epochs: 100
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 128
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.05

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 22:53:33.196431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 22:53:33.200929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run hearty-sweep-7
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/46cpc1mb
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_225331-46cpc1mb
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0007271818421781063 	Val Loss:  0.0003599997892975807
Epoch:  11 	Train Loss:  0.0007272015891969204 	Val Loss:  0.00035999960973858835
Epoch:  21 	Train Loss:  0.0007272009471058845 	Val Loss:  0.00036000024527311326
Epoch:  31 	Train Loss:  0.0007272012446820736 	Val Loss:  0.00035999975502490995
Epoch:  41 	Train Loss:  0.0007272010500729084 	Val Loss:  0.0003600002080202103
Epoch:  51 	Train Loss:  0.0007272005109488964 	Val Loss:  0.00036000031009316444
Epoch:  61 	Train Loss:  0.0007272014959156513 	Val Loss:  0.00035999991595745084
Epoch:  71 	Train Loss:  0.0007272004869580269 	Val Loss:  0.0003599994979798794
Epoch:  81 	Train Loss:  0.0007272015263140202 	Val Loss:  0.00035999989211559294
Epoch:  91 	Train Loss:  0.000727200962305069 	Val Loss:  0.00036000047475099565
wandb: Waiting for W&B process to finish, PID 3740671
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_225331-46cpc1mb/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_225331-46cpc1mb/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 0.00073
wandb:    Train Acc 0.09881
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 379
wandb:   _timestamp 1619578790
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE ▁██████████
wandb:    Train Acc █▂▁▁▁▁▂▂▁▂▂
wandb:      Val MSE ▃▂▆▃▆▇▄▁▄█▅
wandb:      Val Acc ▁▁▁▁▁▁▁▁▁▁▁
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced hearty-sweep-7: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/46cpc1mb
wandb: Agent Starting Run: vldtyc4x with config:
wandb: 	batch_size: 256
wandb: 	criterion: mse
wandb: 	epochs: 500
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 128
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.01

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 22:59:56.736206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 22:59:56.740600: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run cerulean-sweep-8
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/vldtyc4x
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_225954-vldtyc4x
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.00035332676395773886 	Val Loss:  0.0003605457723140717
Epoch:  51 	Train Loss:  0.00035182671427726745 	Val Loss:  0.00035898053869605067
Epoch:  101 	Train Loss:  0.0003514433746039867 	Val Loss:  0.0003585806027054787
Epoch:  151 	Train Loss:  0.000351473156362772 	Val Loss:  0.00035861561223864553
Epoch:  201 	Train Loss:  0.00035166585192084314 	Val Loss:  0.0003588143534958363
Epoch:  251 	Train Loss:  0.0003518953774869442 	Val Loss:  0.0003590567119419575
Epoch:  301 	Train Loss:  0.0003521145662665367 	Val Loss:  0.0003592876076698303
Epoch:  351 	Train Loss:  0.00035230173617601393 	Val Loss:  0.0003594838425517082
Epoch:  401 	Train Loss:  0.0003524456736445427 	Val Loss:  0.0003596391469240189
Epoch:  451 	Train Loss:  0.0003525595858693123 	Val Loss:  0.00035975575372576714
wandb: Waiting for W&B process to finish, PID 3750061
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_225954-vldtyc4x/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_225954-vldtyc4x/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.00035
wandb:    Train Acc 0.15414
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1159
wandb:        _step 10
wandb:     _runtime 1373
wandb:   _timestamp 1619580167
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▂▁▁▂▃▃▄▅▅▅
wandb:    Train Acc ▁▃▅▇██████▇
wandb:      Val MSE █▂▁▁▂▃▄▄▅▅▅
wandb:      Val Acc ▁▅███▇▇▆▅▄▂
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced cerulean-sweep-8: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/vldtyc4x
wandb: Agent Starting Run: z615bbu1 with config:
wandb: 	batch_size: 256
wandb: 	criterion: cross_entropy
wandb: 	epochs: 500
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 512
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.001

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 23:22:53.788562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 23:22:53.793263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run fine-sweep-9
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/z615bbu1
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_232251-z615bbu1
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.00901938708782196 	Val Loss:  0.009197855806350708
Epoch:  51 	Train Loss:  0.008399438424110412 	Val Loss:  0.008554740262031554
Epoch:  101 	Train Loss:  0.008059121012687683 	Val Loss:  0.00822475552558899
Epoch:  151 	Train Loss:  0.007842425038814545 	Val Loss:  0.008025416445732117
Epoch:  201 	Train Loss:  0.007700378165245056 	Val Loss:  0.007893506622314453
Epoch:  251 	Train Loss:  0.007582876572608948 	Val Loss:  0.007793446803092957
Epoch:  301 	Train Loss:  0.007483612587451935 	Val Loss:  0.0077133607506752015
Epoch:  351 	Train Loss:  0.007399272747039795 	Val Loss:  0.007646285498142243
Epoch:  401 	Train Loss:  0.00731764815568924 	Val Loss:  0.0075842483043670654
Epoch:  451 	Train Loss:  0.00722441132068634 	Val Loss:  0.007516609525680542
wandb: Waiting for W&B process to finish, PID 3834852
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_232251-z615bbu1/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_232251-z615bbu1/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.00714
wandb:    Train Acc 0.51683
wandb:      Val MSE 0.00746
wandb:      Val Acc 0.6144
wandb:        _step 10
wandb:     _runtime 1189
wandb:   _timestamp 1619581361
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▆▄▄▃▃▂▂▂▁▁
wandb:    Train Acc ▁▄▅▅▆▆▇▇▇██
wandb:      Val MSE █▅▄▃▃▂▂▂▁▁▁
wandb:      Val Acc ▁▄▅▆▆▇▇▇▇██
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced fine-sweep-9: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/z615bbu1
wandb: Agent Starting Run: 0yyszooe with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 1000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-27 23:42:47.838704: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-27 23:42:47.843841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run efficient-sweep-10
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/0yyszooe
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210427_234246-0yyszooe
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0014068276333808899 	Val Loss:  0.0003596945866942406
Epoch:  101 	Train Loss:  0.001278785425722599 	Val Loss:  0.00032618035450577735
Epoch:  201 	Train Loss:  0.001184610708206892 	Val Loss:  0.0003020526207983494
Epoch:  301 	Train Loss:  0.0010759348179399967 	Val Loss:  0.0002750981986522675
Epoch:  401 	Train Loss:  0.0009923873768001796 	Val Loss:  0.0002553933966904879
Epoch:  501 	Train Loss:  0.0009291431033611298 	Val Loss:  0.0002401617392897606
Epoch:  601 	Train Loss:  0.0008818932916969061 	Val Loss:  0.00022966502867639065
Epoch:  701 	Train Loss:  0.0008393888781964779 	Val Loss:  0.000220807371661067
Epoch:  801 	Train Loss:  0.0008015942418575287 	Val Loss:  0.00021345171481370925
Epoch:  901 	Train Loss:  0.0007709038762748242 	Val Loss:  0.0002073552019894123
wandb: Waiting for W&B process to finish, PID 3869473
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_234246-0yyszooe/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210427_234246-0yyszooe/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 999
wandb:    Train MSE 0.00075
wandb:    Train Acc 0.50041
wandb:      Val MSE 0.0002
wandb:      Val Acc 0.6138
wandb:        _step 10
wandb:     _runtime 4704
wandb:   _timestamp 1619586070
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▇▆▄▄▃▂▂▂▁▁
wandb:    Train Acc ▁▃▄▅▆▆▇▇▇██
wandb:      Val MSE █▇▅▄▃▃▂▂▁▁▁
wandb:      Val Acc ▁▄▅▆▆▇▇▇███
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▄▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▄▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced efficient-sweep-10: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/0yyszooe
wandb: Agent Starting Run: sh9fr605 with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 500
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 512
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.05

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 01:01:17.113620: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 01:01:17.118580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run proud-sweep-11
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/sh9fr605
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_010115-sh9fr605
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0014076970584690571 	Val Loss:  0.0003600064940750599
Epoch:  51 	Train Loss:  0.0014076009352505206 	Val Loss:  0.00035999990180134774
Epoch:  101 	Train Loss:  0.001407600937783718 	Val Loss:  0.00035999994650483133
Epoch:  151 	Train Loss:  0.001407601003497839 	Val Loss:  0.0003599999397993088
Epoch:  201 	Train Loss:  0.0014076009587943555 	Val Loss:  0.0003599999651312828
Epoch:  251 	Train Loss:  0.001407600889056921 	Val Loss:  0.0003600000724196434
Epoch:  301 	Train Loss:  0.0014076008693873882 	Val Loss:  0.0003599999390542507
Epoch:  351 	Train Loss:  0.001407600779235363 	Val Loss:  0.00036000017300248145
Epoch:  401 	Train Loss:  0.0014076008747518063 	Val Loss:  0.00035999993756413457
Epoch:  451 	Train Loss:  0.0014076012372970582 	Val Loss:  0.00035999997034668924
wandb: Waiting for W&B process to finish, PID 4060770
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
[lambda01][[12032,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(57) failed: Connection reset by peer (104)
[lambda01][[12032,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(58) failed: Connection reset by peer (104)
[lambda01][[12032,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(19) failed: Connection reset by peer (104)
[lambda01][[12032,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(21) failed: Connection reset by peer (104)
[lambda01][[12032,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(40) failed: Connection reset by peer (104)
[lambda01][[12032,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(50) failed: Connection reset by peer (104)
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_010115-sh9fr605/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_010115-sh9fr605/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.00141
wandb:    Train Acc 0.09784
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 2516
wandb:   _timestamp 1619588591
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc █▂▁▁▁▁▁▁▁▁▁
wandb:      Val MSE █▁▁▁▁▁▁▁▁▁▁
wandb:      Val Acc ▁▁▁▁▁▁▁▁▁▁▁
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced proud-sweep-11: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/sh9fr605
wandb: Agent Starting Run: 6qfwj0lu with config:
wandb: 	batch_size: 64
wandb: 	criterion: cross_entropy
wandb: 	epochs: 500
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 16
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 01:43:17.510068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 01:43:17.514587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run swept-sweep-12
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/6qfwj0lu
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_014315-6qfwj0lu
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.03591048892021179 	Val Loss:  0.009132642602920533
Epoch:  51 	Train Loss:  0.030631240375041963 	Val Loss:  0.007839865195751191
Epoch:  101 	Train Loss:  0.02969428574562073 	Val Loss:  0.007649590718746185
Epoch:  151 	Train Loss:  0.029159209904670715 	Val Loss:  0.007530648970603943
Epoch:  201 	Train Loss:  0.02886501610994339 	Val Loss:  0.007465948283672333
Epoch:  251 	Train Loss:  0.028695127050876616 	Val Loss:  0.0074740958213806155
Epoch:  301 	Train Loss:  0.028606940293312073 	Val Loss:  0.0074308515310287475
Epoch:  351 	Train Loss:  0.028542980675697327 	Val Loss:  0.007388406109809876
Epoch:  401 	Train Loss:  0.02849339736223221 	Val Loss:  0.007371792876720428
Epoch:  451 	Train Loss:  0.02846351867198944 	Val Loss:  0.007373872673511505
wandb: Waiting for W&B process to finish, PID 4096926
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_014315-6qfwj0lu/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_014315-6qfwj0lu/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.02846
wandb:    Train Acc 0.62807
wandb:      Val MSE 0.00739
wandb:      Val Acc 0.6489
wandb:        _step 10
wandb:     _runtime 2562
wandb:   _timestamp 1619591157
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▃▂▂▁▁▁▁▁▁▁
wandb:    Train Acc ▁▅▆▆▇▇▇████
wandb:      Val MSE █▃▂▂▁▁▁▁▁▁▁
wandb:      Val Acc ▁▆▇▇█▇█████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced swept-sweep-12: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/6qfwj0lu
wandb: Agent Starting Run: ad624q8o with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.8
wandb: 	num_kernels_layer1: 16
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 256
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 02:26:03.479934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 02:26:03.485074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run chocolate-sweep-13
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/ad624q8o
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_022601-ad624q8o
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.001407403026074171 	Val Loss:  0.0003596262700855732
Epoch:  501 	Train Loss:  0.0013486785221099853 	Val Loss:  0.00034426780566573144
Epoch:  1001 	Train Loss:  0.0013485403092205524 	Val Loss:  0.0003442061379551887
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: Network error resolved after 0:02:12.091731, resuming normal operation.
wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)
wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)
wandb: Network error (HTTPError), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)
wandb: Network error resolved after 0:00:31.623952, resuming normal operation.
Epoch:  1501 	Train Loss:  0.0013483202792704105 	Val Loss:  0.0003441727608442307
Epoch:  2001 	Train Loss:  0.0013483425650000571 	Val Loss:  0.0003441540353000164
Epoch:  2501 	Train Loss:  0.0013482976478338242 	Val Loss:  0.0003441478252410889
Epoch:  3001 	Train Loss:  0.0013483059184253216 	Val Loss:  0.00034414338916540144
Epoch:  3501 	Train Loss:  0.001348326020538807 	Val Loss:  0.0003441411957144737
Epoch:  4001 	Train Loss:  0.001348289140611887 	Val Loss:  0.000344139414280653
Epoch:  4501 	Train Loss:  0.001348255437463522 	Val Loss:  0.0003441376343369484
wandb: Waiting for W&B process to finish, PID 4137270
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_022601-ad624q8o/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_022601-ad624q8o/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.00135
wandb:    Train Acc 0.17864
wandb:      Val MSE 0.00034
wandb:      Val Acc 0.1819
wandb:        _step 10
wandb:     _runtime 25234
wandb:   _timestamp 1619616395
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁██████████
wandb:      Val MSE █▁▁▁▁▁▁▁▁▁▁
wandb:      Val Acc ▁██████████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▄▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▄▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced chocolate-sweep-13: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/ad624q8o
wandb: Agent Starting Run: hmehv115 with config:
wandb: 	batch_size: 124
wandb: 	criterion: mse
wandb: 	epochs: 1000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 16
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 128
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 09:26:41.703377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 09:26:41.708336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run grateful-sweep-14
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/hmehv115
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_092639-hmehv115
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0007270647294819355 	Val Loss:  0.00035980348736047745
Epoch:  101 	Train Loss:  0.0007039386248588562 	Val Loss:  0.00034790742099285126
Epoch:  201 	Train Loss:  0.0006991508513689041 	Val Loss:  0.00034546674340963366
Epoch:  301 	Train Loss:  0.00069821308106184 	Val Loss:  0.0003449848271906376
Epoch:  401 	Train Loss:  0.0006977869021892548 	Val Loss:  0.0003447828933596611
Epoch:  501 	Train Loss:  0.0006975637753307819 	Val Loss:  0.000344666513800621
Epoch:  601 	Train Loss:  0.0006974436816573143 	Val Loss:  0.0003445908464491367
Epoch:  701 	Train Loss:  0.0006973163253068924 	Val Loss:  0.00034453453868627546
Epoch:  801 	Train Loss:  0.0006972217182815074 	Val Loss:  0.0003444906733930111
Epoch:  901 	Train Loss:  0.0006971122336387634 	Val Loss:  0.0003444575235247612
wandb: Waiting for W&B process to finish, PID 774358
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_092639-hmehv115/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_092639-hmehv115/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 999
wandb:    Train MSE 0.0007
wandb:    Train Acc 0.18027
wandb:      Val MSE 0.00034
wandb:      Val Acc 0.1804
wandb:        _step 10
wandb:     _runtime 3238
wandb:   _timestamp 1619619637
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▃▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁█▇▇▇▇▇▇▇▇▇
wandb:      Val MSE █▃▁▁▁▁▁▁▁▁▁
wandb:      Val Acc ▁█▇▇▇▇▇▇▇▇▇
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced grateful-sweep-14: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/hmehv115
wandb: Agent Starting Run: 67vj8osj with config:
wandb: 	batch_size: 256
wandb: 	criterion: mse
wandb: 	epochs: 100
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 128
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.05

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 10:20:45.846461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 10:20:45.852968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run absurd-sweep-15
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/67vj8osj
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_102043-67vj8osj
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0003531895619630814 	Val Loss:  0.00036034177020192147
Epoch:  11 	Train Loss:  0.0003528489054739475 	Val Loss:  0.00036001353040337564
Epoch:  21 	Train Loss:  0.00035273426800966264 	Val Loss:  0.0003599046751856804
Epoch:  31 	Train Loss:  0.00035271178498864176 	Val Loss:  0.00035988768190145493
Epoch:  41 	Train Loss:  0.00035272339940071106 	Val Loss:  0.0003599037326872349
Epoch:  51 	Train Loss:  0.0003527438607811928 	Val Loss:  0.00035992728620767595
Epoch:  61 	Train Loss:  0.0003527629166841507 	Val Loss:  0.0003599486194550991
Epoch:  71 	Train Loss:  0.00035277852043509486 	Val Loss:  0.00035996501818299294
Epoch:  81 	Train Loss:  0.00035278725862503054 	Val Loss:  0.0003599765717983246
Epoch:  91 	Train Loss:  0.0003527955010533333 	Val Loss:  0.0003599842756986618
wandb: Waiting for W&B process to finish, PID 906440
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_102043-67vj8osj/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_102043-67vj8osj/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 0.00035
wandb:    Train Acc 0.10691
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 257
wandb:   _timestamp 1619619900
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▃▁▁▁▁▂▂▂▂▂
wandb:    Train Acc ▁▃▄▆▇████▇▇
wandb:      Val MSE █▃▁▁▁▂▂▂▂▂▃
wandb:      Val Acc ▁▃▅▇█▇▆▄▄▄▄
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced absurd-sweep-15: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/67vj8osj
wandb: Agent Starting Run: cb91v2j0 with config:
wandb: 	batch_size: 256
wandb: 	criterion: mse
wandb: 	epochs: 100
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 128
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 10:25:06.388680: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 10:25:06.393740: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run gallant-sweep-16
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/cb91v2j0
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_102504-cb91v2j0
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0003525730387866497 	Val Loss:  0.00035939532592892646
Epoch:  11 	Train Loss:  0.0003447193892300129 	Val Loss:  0.00035109888240695
Epoch:  21 	Train Loss:  0.00033648649647831917 	Val Loss:  0.00034253293797373774
Epoch:  31 	Train Loss:  0.0003306500504910946 	Val Loss:  0.0003364481560885906
Epoch:  41 	Train Loss:  0.0003261072887480259 	Val Loss:  0.0003317240856587887
Epoch:  51 	Train Loss:  0.0003223311758041382 	Val Loss:  0.0003277982547879219
Epoch:  61 	Train Loss:  0.0003191141501069069 	Val Loss:  0.0003244194187223911
Epoch:  71 	Train Loss:  0.0003162212173640728 	Val Loss:  0.00032136042416095736
Epoch:  81 	Train Loss:  0.0003133314408361912 	Val Loss:  0.0003184265933930874
Epoch:  91 	Train Loss:  0.00031047263607382773 	Val Loss:  0.0003154937133193016
wandb: Waiting for W&B process to finish, PID 911808
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_102504-cb91v2j0/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_102504-cb91v2j0/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 0.00031
wandb:    Train Acc 0.29078
wandb:      Val MSE 0.00031
wandb:      Val Acc 0.3567
wandb:        _step 10
wandb:     _runtime 345
wandb:   _timestamp 1619620249
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▇▅▅▄▃▃▂▂▁▁
wandb:    Train Acc ▁▄▅▆▆▇▇▇███
wandb:      Val MSE █▇▅▅▄▃▃▂▂▁▁
wandb:      Val Acc ▁▄▅▆▆▇▇▇▇██
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced gallant-sweep-16: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/cb91v2j0
wandb: Agent Starting Run: jiap2b5c with config:
wandb: 	batch_size: 124
wandb: 	criterion: mse
wandb: 	epochs: 500
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.001

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 10:30:56.663355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 10:30:56.669630: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run spring-sweep-17
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/jiap2b5c
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_103054-jiap2b5c
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.000728288269340992 	Val Loss:  0.00036030713468790057
Epoch:  51 	Train Loss:  0.000679277269244194 	Val Loss:  0.0003357060670852661
Epoch:  101 	Train Loss:  0.0006613028234243392 	Val Loss:  0.00032683694586157797
Epoch:  151 	Train Loss:  0.0006444290326535701 	Val Loss:  0.00031835001036524774
Epoch:  201 	Train Loss:  0.0006257116587460041 	Val Loss:  0.00030908126831054685
Epoch:  251 	Train Loss:  0.0006081420357525348 	Val Loss:  0.0003006238803267479
Epoch:  301 	Train Loss:  0.0005933593398332596 	Val Loss:  0.0002935445599257946
Epoch:  351 	Train Loss:  0.0005753218850493431 	Val Loss:  0.00028480484187603
Epoch:  401 	Train Loss:  0.0005530651670694352 	Val Loss:  0.0002740504615008831
Epoch:  451 	Train Loss:  0.0005319389867782593 	Val Loss:  0.0002638558775186539
wandb: Waiting for W&B process to finish, PID 917694
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_103054-jiap2b5c/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_103054-jiap2b5c/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.00051
wandb:    Train Acc 0.37789
wandb:      Val MSE 0.00026
wandb:      Val Acc 0.4985
wandb:        _step 10
wandb:     _runtime 1553
wandb:   _timestamp 1619621807
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▆▆▅▅▄▄▃▂▂▁
wandb:    Train Acc ▁▄▅▅▆▆▇▇▇██
wandb:      Val MSE █▆▆▅▅▄▄▃▂▂▁
wandb:      Val Acc ▁▄▅▅▆▆▇▇▇██
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced spring-sweep-17: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/jiap2b5c
wandb: Agent Starting Run: 63d9jcyt with config:
wandb: 	batch_size: 256
wandb: 	criterion: mse
wandb: 	epochs: 1000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 256
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.01

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 10:56:53.549700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 10:56:53.555964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run celestial-sweep-18
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/63d9jcyt
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_105651-63d9jcyt
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.00035268211349844935 	Val Loss:  0.00035983590930700304
Epoch:  101 	Train Loss:  0.00035156440615653994 	Val Loss:  0.000358695725351572
Epoch:  201 	Train Loss:  0.0003516873699426651 	Val Loss:  0.00035882958099246027
Epoch:  301 	Train Loss:  0.00035205540135502814 	Val Loss:  0.00035921594351530074
Epoch:  401 	Train Loss:  0.00035238742426037787 	Val Loss:  0.0003595642477273941
Epoch:  501 	Train Loss:  0.00035260649830102923 	Val Loss:  0.00035979339107871056
Epoch:  601 	Train Loss:  0.0003527215753495693 	Val Loss:  0.00035991576910018923
Epoch:  701 	Train Loss:  0.00035277467742562296 	Val Loss:  0.0003599711962044239
Epoch:  801 	Train Loss:  0.00035279461950063707 	Val Loss:  0.00035999290272593497
Epoch:  901 	Train Loss:  0.00035280120924115183 	Val Loss:  0.0003600000783801079
wandb: Waiting for W&B process to finish, PID 1023879
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_105651-63d9jcyt/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_105651-63d9jcyt/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 999
wandb:    Train MSE 0.00035
wandb:    Train Acc 0.12052
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 2374
wandb:   _timestamp 1619624185
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE ▇▁▂▄▆▇█████
wandb:    Train Acc ▂▇███▇▆▅▃▂▁
wandb:      Val MSE ▇▁▂▄▆▇█████
wandb:      Val Acc ▅███▇▆▄▂▁▁▁
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced celestial-sweep-18: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/63d9jcyt
wandb: Agent Starting Run: 25v937ru with config:
wandb: 	batch_size: 64
wandb: 	criterion: cross_entropy
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.8
wandb: 	num_kernels_layer1: 16
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 256
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.01

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 11:36:33.284116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 11:36:33.288788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run youthful-sweep-19
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/25v937ru
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_113631-25v937ru
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0359656364774704 	Val Loss:  0.009184627151489258
Epoch:  501 	Train Loss:  0.030175143847465516 	Val Loss:  0.007755426418781281
Epoch:  1001 	Train Loss:  0.029959215941429137 	Val Loss:  0.007703606069087982
Epoch:  1501 	Train Loss:  0.029870364067554472 	Val Loss:  0.007716281914710999
Epoch:  2001 	Train Loss:  0.02985581691980362 	Val Loss:  0.0076878081560134886
Epoch:  2501 	Train Loss:  0.02982948847055435 	Val Loss:  0.007673925983905793
Epoch:  3001 	Train Loss:  0.029828285644054413 	Val Loss:  0.0076692114472389225
Epoch:  3501 	Train Loss:  0.029794000689983367 	Val Loss:  0.007680335032939911
Epoch:  4001 	Train Loss:  0.029764997954368592 	Val Loss:  0.007665606236457825
Epoch:  4501 	Train Loss:  0.02975044225692749 	Val Loss:  0.00769677631855011
wandb: Waiting for W&B process to finish, PID 1071583
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_113631-25v937ru/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_113631-25v937ru/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.02975
wandb:    Train Acc 0.58375
wandb:      Val MSE 0.00766
wandb:      Val Acc 0.5789
wandb:        _step 10
wandb:     _runtime 25409
wandb:   _timestamp 1619649600
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁▇▇▇███████
wandb:      Val MSE █▁▁▁▁▁▁▁▁▁▁
wandb:      Val Acc ▁▇█████████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced youthful-sweep-19: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/25v937ru
wandb: Agent Starting Run: f4pubcjz with config:
wandb: 	batch_size: 124
wandb: 	criterion: cross_entropy
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 256
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.05

wandb: wandb version 0.10.27 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 18:40:07.037792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 18:40:07.045550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run sandy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/f4pubcjz
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_184005-f4pubcjz
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.01860619421005249 	Val Loss:  0.009210201644897461
Epoch:  501 	Train Loss:  0.018604887862205505 	Val Loss:  0.009210340332984924
Epoch:  1001 	Train Loss:  0.018604886770248415 	Val Loss:  0.009210340785980225
Epoch:  1501 	Train Loss:  0.018604886269569396 	Val Loss:  0.009210340809822082
Epoch:  2001 	Train Loss:  0.018604886589050292 	Val Loss:  0.009210340166091919
Epoch:  2501 	Train Loss:  0.018604886417388916 	Val Loss:  0.009210340094566345
Epoch:  3001 	Train Loss:  0.018604886894226073 	Val Loss:  0.00921034026145935
Epoch:  3501 	Train Loss:  0.018604885807037355 	Val Loss:  0.00921033935546875
Epoch:  4001 	Train Loss:  0.018604886322021483 	Val Loss:  0.009210340785980225
Epoch:  4501 	Train Loss:  0.018604886655807496 	Val Loss:  0.009210339999198914
wandb: Waiting for W&B process to finish, PID 1990301
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_184005-f4pubcjz/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_184005-f4pubcjz/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.0186
wandb:    Train Acc 0.09978
wandb:      Val MSE 0.00921
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 18452
wandb:   _timestamp 1619668057
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁█▆▆▆▅▅▅▅▅▅
wandb:      Val MSE ▁██████████
wandb:      Val Acc █▁▁▁▁▁▁▁▁▁▁
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced sandy-sweep-20: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/f4pubcjz
wandb: Agent Starting Run: 43je8txi with config:
wandb: 	batch_size: 64
wandb: 	criterion: cross_entropy
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.8
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-28 23:47:43.743506: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-28 23:47:43.748920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run toasty-sweep-21
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/43je8txi
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210428_234742-43je8txi
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.03600514174938202 	Val Loss:  0.009207743310928345
Epoch:  501 	Train Loss:  0.03256528976917267 	Val Loss:  0.008320041680335998
Epoch:  1001 	Train Loss:  0.03162128059387207 	Val Loss:  0.008098432099819183
Epoch:  1501 	Train Loss:  0.031192292656898497 	Val Loss:  0.007990296077728271
Epoch:  2001 	Train Loss:  0.030868541016578675 	Val Loss:  0.007915278148651122
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)
wandb: Network error (HTTPError), entering retry loop. See /home/naddeok5/FIM/wandb/run-20210428_234742-43je8txi/logs/debug-internal.log for full traceback.
wandb: Network error resolved after 0:01:07.249012, resuming normal operation.
wandb: Network error resolved after 0:01:58.542961, resuming normal operation.
Epoch:  2501 	Train Loss:  0.03064413601398468 	Val Loss:  0.007864362871646881
Epoch:  3001 	Train Loss:  0.030492534666061402 	Val Loss:  0.007828198182582855
Epoch:  3501 	Train Loss:  0.030326730089187622 	Val Loss:  0.007792949998378753
Epoch:  4001 	Train Loss:  0.03018153829097748 	Val Loss:  0.007761276054382324
Epoch:  4501 	Train Loss:  0.030080130178928376 	Val Loss:  0.0077396368026733395
wandb: Waiting for W&B process to finish, PID 2787092
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
[lambda01][[24174,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(36) failed: Connection reset by peer (104)
[lambda01][[24174,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(42) failed: Connection reset by peer (104)
[lambda01][[24174,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(56) failed: Connection reset by peer (104)
[lambda01][[24174,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(57) failed: Connection reset by peer (104)
[lambda01][[24174,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(19) failed: Connection reset by peer (104)
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_234742-43je8txi/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210428_234742-43je8txi/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.03
wandb:    Train Acc 0.50136
wandb:      Val MSE 0.00772
wandb:      Val Acc 0.554
wandb:        _step 10
wandb:     _runtime 29930
wandb:   _timestamp 1619697992
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▄▃▂▂▂▂▁▁▁▁
wandb:    Train Acc ▁▄▆▆▇▇▇▇███
wandb:      Val MSE █▄▃▂▂▂▁▁▁▁▁
wandb:      Val Acc ▁▅▆▇▇▇█████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced toasty-sweep-21: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/43je8txi
wandb: Agent Starting Run: cn17d5v4 with config:
wandb: 	batch_size: 256
wandb: 	criterion: cross_entropy
wandb: 	epochs: 500
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 256
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 08:06:38.845157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 08:06:38.849595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run gallant-sweep-22
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/cn17d5v4
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_080637-cn17d5v4
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.008517093892097474 	Val Loss:  0.008389288449287415
Epoch:  51 	Train Loss:  0.007618756651878357 	Val Loss:  0.007846107304096222
Epoch:  101 	Train Loss:  0.00756722373008728 	Val Loss:  0.0077221782803535465
Epoch:  151 	Train Loss:  0.007556665110588074 	Val Loss:  0.007798805034160614
Epoch:  201 	Train Loss:  0.007539721248149871 	Val Loss:  0.007845587277412415
Epoch:  251 	Train Loss:  0.007541041803359985 	Val Loss:  0.007774405777454376
Epoch:  301 	Train Loss:  0.007536878795623779 	Val Loss:  0.007705372762680054
Epoch:  351 	Train Loss:  0.007536767265796661 	Val Loss:  0.007793322479724884
Epoch:  401 	Train Loss:  0.007568508229255676 	Val Loss:  0.007770886933803558
Epoch:  451 	Train Loss:  0.0075452881503105165 	Val Loss:  0.007665999591350555
wandb: Waiting for W&B process to finish, PID 3809713
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_080637-cn17d5v4/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_080637-cn17d5v4/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.00754
wandb:    Train Acc 0.54842
wandb:      Val MSE 0.00771
wandb:      Val Acc 0.5493
wandb:        _step 10
wandb:     _runtime 1170
wandb:   _timestamp 1619699167
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▂▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁▇▇████████
wandb:      Val MSE █▃▂▂▃▂▁▂▂▁▁
wandb:      Val Acc ▁▆▇▇▆▇█▇▇██
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced gallant-sweep-22: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/cn17d5v4
wandb: Agent Starting Run: jtk79gbl with config:
wandb: 	batch_size: 124
wandb: 	criterion: cross_entropy
wandb: 	epochs: 500
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 64
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 08:26:14.131746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 08:26:14.136317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run morning-sweep-23
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/jtk79gbl
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_082612-jtk79gbl
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.01838035382270813 	Val Loss:  0.008950305056571961
Epoch:  51 	Train Loss:  0.015213326833248138 	Val Loss:  0.007593145334720611
Epoch:  101 	Train Loss:  0.014839254848957062 	Val Loss:  0.00742154346704483
Epoch:  151 	Train Loss:  0.014704596290588378 	Val Loss:  0.00743141576051712
Epoch:  201 	Train Loss:  0.014669216120243073 	Val Loss:  0.007545706951618195
Epoch:  251 	Train Loss:  0.01464424941778183 	Val Loss:  0.007344800865650177
Epoch:  301 	Train Loss:  0.01461331120967865 	Val Loss:  0.007358603501319885
Epoch:  351 	Train Loss:  0.01460799497127533 	Val Loss:  0.007344255435466766
Epoch:  401 	Train Loss:  0.014585283846855163 	Val Loss:  0.007346059584617615
Epoch:  451 	Train Loss:  0.014579629459381103 	Val Loss:  0.007311066365242005
wandb: Waiting for W&B process to finish, PID 3923429
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_082612-jtk79gbl/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_082612-jtk79gbl/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.01457
wandb:    Train Acc 0.66483
wandb:      Val MSE 0.00736
wandb:      Val Acc 0.6531
wandb:        _step 10
wandb:     _runtime 1839
wandb:   _timestamp 1619701011
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▂▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁▆▇▇▇██████
wandb:      Val MSE █▂▁▂▂▁▁▁▁▁▁
wandb:      Val Acc ▁▇█▇▇██████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced morning-sweep-23: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/jtk79gbl
wandb: Agent Starting Run: gocglant with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 128
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 08:56:57.840189: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 08:56:57.844607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run distinctive-sweep-24
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/gocglant
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_085656-gocglant
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0013796225392818451 	Val Loss:  0.00034259424284100533
Epoch:  501 	Train Loss:  5.6807807609366135e-05 	Val Loss:  0.00023985587693750858
Epoch:  1001 	Train Loss:  4.655051096471652e-05 	Val Loss:  0.0002441573452204466
Epoch:  1501 	Train Loss:  4.137598583894942e-05 	Val Loss:  0.0002472447820007801
Epoch:  2001 	Train Loss:  3.86521918101289e-05 	Val Loss:  0.0002482374932616949
Epoch:  2501 	Train Loss:  3.6225645800602705e-05 	Val Loss:  0.0002503687996417284
Epoch:  3001 	Train Loss:  3.468668322610029e-05 	Val Loss:  0.00025124285630881784
Epoch:  3501 	Train Loss:  3.359954276011422e-05 	Val Loss:  0.0002522653739899397
Epoch:  4001 	Train Loss:  3.2869617826802366e-05 	Val Loss:  0.0002525554031133652
Epoch:  4501 	Train Loss:  3.196195732864908e-05 	Val Loss:  0.00025317548140883447
wandb: Waiting for W&B process to finish, PID 3941225
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_085656-gocglant/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_085656-gocglant/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 3e-05
wandb:    Train Acc 0.97482
wandb:      Val MSE 0.00025
wandb:      Val Acc 0.6323
wandb:        _step 10
wandb:     _runtime 28485
wandb:   _timestamp 1619729501
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁▇█████████
wandb:      Val MSE █▁▁▂▂▂▂▂▂▂▂
wandb:      Val Acc ▁██████████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced distinctive-sweep-24: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/gocglant
wandb: Agent Starting Run: 7ya2k870 with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 500
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 256
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.005

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 16:51:48.763818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 16:51:48.770684: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run lunar-sweep-25
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/7ya2k870
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_165146-7ya2k870
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0014048099085688592 	Val Loss:  0.0003584538631141186
Epoch:  51 	Train Loss:  0.0013495532239973546 	Val Loss:  0.00034446685910224917
wandb: ERROR Error while calling W&B API: Error 1053: Server shutdown in progress (<Response [500]>)
Epoch:  101 	Train Loss:  0.0013492109543085098 	Val Loss:  0.0003443298861384392
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: Network error (HTTPError), entering retry loop. See /home/naddeok5/FIM/wandb/run-20210429_165146-7ya2k870/logs/debug-internal.log for full traceback.
Epoch:  151 	Train Loss:  0.0013488036632537841 	Val Loss:  0.0003442412607371807
Epoch:  201 	Train Loss:  0.0013485496421158313 	Val Loss:  0.0003441949561238289
Epoch:  251 	Train Loss:  0.001348567877113819 	Val Loss:  0.00034416721016168595
Epoch:  301 	Train Loss:  0.0013483981050550937 	Val Loss:  0.00034414497911930083
Epoch:  351 	Train Loss:  0.0013483344782888888 	Val Loss:  0.00034411266669631
Epoch:  401 	Train Loss:  0.0013482834360003472 	Val Loss:  0.00034411066994071007
Epoch:  451 	Train Loss:  0.0013482666771113872 	Val Loss:  0.00034408478736877444
wandb: Waiting for W&B process to finish, PID 546584
wandb: Program ended successfully.
500 response executing GraphQL.
{"error":"driver: bad connection"}

500 response executing GraphQL.
{"error":"driver: bad connection"}

502 response executing GraphQL.

<html><head>
<meta http-equiv="content-type" content="text/html;charset=utf-8">
<title>502 Server Error</title>
</head>
<body text=#000000 bgcolor=#ffffff>
<h1>Error: Server Error</h1>
<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>
<h2></h2>
</body></html>

502 response executing GraphQL.

<html><head>
<meta http-equiv="content-type" content="text/html;charset=utf-8">
<title>502 Server Error</title>
</head>
<body text=#000000 bgcolor=#ffffff>
<h1>Error: Server Error</h1>
<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>
<h2></h2>
</body></html>

502 response executing GraphQL.

<html><head>
<meta http-equiv="content-type" content="text/html;charset=utf-8">
<title>502 Server Error</title>
</head>
<body text=#000000 bgcolor=#ffffff>
<h1>Error: Server Error</h1>
<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>
<h2></h2>
</body></html>

502 response executing GraphQL.

<html><head>
<meta http-equiv="content-type" content="text/html;charset=utf-8">
<title>502 Server Error</title>
</head>
<body text=#000000 bgcolor=#ffffff>
<h1>Error: Server Error</h1>
<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>
<h2></h2>
</body></html>

wandb: Network error resolved after 1:05:41.222316, resuming normal operation.
wandb: Network error resolved after 1:07:06.907139, resuming normal operation.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_165146-7ya2k870/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_165146-7ya2k870/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 499
wandb:    Train MSE 0.00135
wandb:    Train Acc 0.17917
wandb:      Val MSE 0.00034
wandb:      Val Acc 0.1807
wandb:        _step 10
wandb:     _runtime 2325
wandb:   _timestamp 1619731831
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▁▁▁▁▁▁▁▁▁
wandb:    Train Acc ▁████▇▇▇▇▇▇
wandb:      Val MSE █▁▁▁▁▁▁▁▁▁▁
wandb:      Val Acc ▁██▇▇▇▇▇▇▇▇
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced lunar-sweep-25: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/7ya2k870
wandb: Agent Starting Run: 1c19hdnm with config:
wandb: 	batch_size: 256
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.001
wandb: 	momentum: 0
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 16
wandb: 	num_kernels_layer3: 1024
wandb: 	num_nodes_fc_layer: 128
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.01

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 18:07:22.107723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 18:07:22.112390: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run crimson-sweep-26
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/1c19hdnm
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_180720-1c19hdnm
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0003530737641453743 	Val Loss:  0.0003602843053638935
Epoch:  501 	Train Loss:  0.0003523828272521496 	Val Loss:  0.0003595604836940765
Epoch:  1001 	Train Loss:  0.0003527949431538582 	Val Loss:  0.0003599945932626724
Epoch:  1501 	Train Loss:  0.0003528000415861607 	Val Loss:  0.0003600001111626625
Epoch:  2001 	Train Loss:  0.00035280000686645506 	Val Loss:  0.0003600000321865082
Epoch:  2501 	Train Loss:  0.00035280000984668733 	Val Loss:  0.000360000005364418
Epoch:  3001 	Train Loss:  0.00035280000790953637 	Val Loss:  0.00036000000834465024
Epoch:  3501 	Train Loss:  0.0003528000059723854 	Val Loss:  0.0003600000225007534
Epoch:  4001 	Train Loss:  0.00035280000999569894 	Val Loss:  0.00036000001430511473
Epoch:  4501 	Train Loss:  0.00035280000656843184 	Val Loss:  0.0003600000075995922
wandb: Waiting for W&B process to finish, PID 660444
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
[lambda01][[52656,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(38) failed: Connection reset by peer (104)
[lambda01][[52656,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(55) failed: Connection reset by peer (104)
[lambda01][[52656,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(56) failed: Connection reset by peer (104)
[lambda01][[52656,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(57) failed: Connection reset by peer (104)
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_180720-1c19hdnm/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_180720-1c19hdnm/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.00035
wandb:    Train Acc 0.10552
wandb:      Val MSE 0.00036
wandb:      Val Acc 0.1
wandb:        _step 10
wandb:     _runtime 12574
wandb:   _timestamp 1619746614
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▁▅▅▅▅▅▅▅▅▅
wandb:    Train Acc ▂█▅▃▃▂▂▁▁▁▁
wandb:      Val MSE █▁▅▅▅▅▅▅▅▅▅
wandb:      Val Acc ▃█▁▁▁▁▁▁▁▁▁
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▄▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▄▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced crimson-sweep-26: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/1c19hdnm
wandb: Agent Starting Run: 2r1azn9e with config:
wandb: 	batch_size: 124
wandb: 	criterion: mse
wandb: 	epochs: 100
wandb: 	learning_rate: 0.1
wandb: 	momentum: 0.8
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 256
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 21:37:00.913096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 21:37:00.917609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run rich-sweep-27
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/2r1azn9e
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_213658-2r1azn9e
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0006805151452124119 	Val Loss:  0.0003191689245402813
Epoch:  11 	Train Loss:  0.0003508048465102911 	Val Loss:  0.00018536062613129617
Epoch:  21 	Train Loss:  0.00023511050395667553 	Val Loss:  0.00017136832065880298
Epoch:  31 	Train Loss:  0.00013320875788107515 	Val Loss:  0.00017801377438008786
Epoch:  41 	Train Loss:  6.389944850699976e-05 	Val Loss:  0.00018400406017899512
Epoch:  51 	Train Loss:  3.941331512061879e-05 	Val Loss:  0.00018959277179092168
Epoch:  61 	Train Loss:  3.0745767288753995e-05 	Val Loss:  0.00019253804851323365
Epoch:  71 	Train Loss:  2.6556317495851544e-05 	Val Loss:  0.0001945232830941677
Epoch:  81 	Train Loss:  2.407301538682077e-05 	Val Loss:  0.00019655041471123696
Epoch:  91 	Train Loss:  2.1958903929335065e-05 	Val Loss:  0.00019668677523732185
wandb: Waiting for W&B process to finish, PID 1620877
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_213658-2r1azn9e/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_213658-2r1azn9e/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 99
wandb:    Train MSE 2e-05
wandb:    Train Acc 0.88926
wandb:      Val MSE 0.0002
wandb:      Val Acc 0.6864
wandb:        _step 10
wandb:     _runtime 312
wandb:   _timestamp 1619746930
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▅▃▂▁▁▁▁▁▁▁
wandb:    Train Acc ▁▄▅▆▇▇▇████
wandb:      Val MSE █▂▁▁▂▂▂▂▂▂▂
wandb:      Val Acc ▁▇█████████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▅▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▅▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced rich-sweep-27: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/2r1azn9e
wandb: Agent Starting Run: b9p1tyce with config:
wandb: 	batch_size: 64
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0.7
wandb: 	num_kernels_layer1: 8
wandb: 	num_kernels_layer2: 64
wandb: 	num_kernels_layer3: 256
wandb: 	num_nodes_fc_layer: 64
wandb: 	optimizer: adadelta
wandb: 	weight_decay: 0.001

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-29 21:42:16.987160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-29 21:42:16.994360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run likely-sweep-28
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/b9p1tyce
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210429_214215-b9p1tyce
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0014070235735177993 	Val Loss:  0.000359254877269268
Epoch:  501 	Train Loss:  0.0009512987024337053 	Val Loss:  0.00024500512592494486
Epoch:  1001 	Train Loss:  0.0008752845812588931 	Val Loss:  0.000227976343780756
Epoch:  1501 	Train Loss:  0.0008473609849065542 	Val Loss:  0.00022202343717217445
Epoch:  2001 	Train Loss:  0.0008282055465131998 	Val Loss:  0.00021819973587989806
Epoch:  2501 	Train Loss:  0.0008165375429391861 	Val Loss:  0.0002158899437636137
Epoch:  3001 	Train Loss:  0.0008075557344406843 	Val Loss:  0.00021381638422608376
Epoch:  3501 	Train Loss:  0.0008007016640901566 	Val Loss:  0.00021232542246580124
Epoch:  4001 	Train Loss:  0.0007957117568701506 	Val Loss:  0.0002109164472669363
Epoch:  4501 	Train Loss:  0.0007923162357509136 	Val Loss:  0.00020999172404408454
wandb: Waiting for W&B process to finish, PID 1624834
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
[lambda01][[4676,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(57) failed: Connection reset by peer (104)
[lambda01][[4676,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(19) failed: Connection reset by peer (104)
[lambda01][[4676,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(36) failed: Connection reset by peer (104)
[lambda01][[4676,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(41) failed: Connection reset by peer (104)
[lambda01][[4676,1],0][btl_tcp.c:559:mca_btl_tcp_recv_blocking] recv(55) failed: Connection reset by peer (104)
wandb: Find user logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_214215-b9p1tyce/logs/debug.log
wandb: Find internal logs for this run at: /home/naddeok5/FIM/wandb/run-20210429_214215-b9p1tyce/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 4999
wandb:    Train MSE 0.00079
wandb:    Train Acc 0.59201
wandb:      Val MSE 0.00021
wandb:      Val Acc 0.6112
wandb:        _step 10
wandb:     _runtime 30461
wandb:   _timestamp 1619777396
wandb: Run history:
wandb:        epoch ▁▂▂▃▄▅▅▆▇▇█
wandb:    Train MSE █▃▂▂▁▁▁▁▁▁▁
wandb:    Train Acc ▁▆▇▇▇██████
wandb:      Val MSE █▃▂▂▁▁▁▁▁▁▁
wandb:      Val Acc ▁▇▇████████
wandb:        _step ▁▂▂▃▄▅▅▆▇▇█
wandb:     _runtime ▁▂▂▃▄▄▅▆▇▇█
wandb:   _timestamp ▁▂▂▃▄▄▅▆▇▇█
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced likely-sweep-28: https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/b9p1tyce
wandb: Agent Starting Run: jeu30rmv with config:
wandb: 	batch_size: 124
wandb: 	criterion: mse
wandb: 	epochs: 5000
wandb: 	learning_rate: 0.01
wandb: 	momentum: 0.9
wandb: 	num_kernels_layer1: 32
wandb: 	num_kernels_layer2: 32
wandb: 	num_kernels_layer3: 256
wandb: 	num_nodes_fc_layer: 32
wandb: 	optimizer: sgd
wandb: 	weight_decay: 0.01

wandb: wandb version 0.10.28 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
2021-04-30 06:10:02.242824: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2021-04-30 06:10:02.247497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
wandb: Tracking run with wandb version 0.10.15
wandb: Syncing run avid-sweep-29
wandb: ⭐️ View project at https://wandb.ai/naddeok/LeNet%20CIFAR10
wandb: 🧹 View sweep at https://wandb.ai/naddeok/LeNet%20CIFAR10/sweeps/jy0kyowp
wandb: 🚀 View run at https://wandb.ai/naddeok/LeNet%20CIFAR10/runs/jeu30rmv
wandb: Run data is saved locally in /home/naddeok5/FIM/wandb/run-20210430_061000-jeu30rmv
wandb: Run `wandb offline` to turn off syncing.

Epoch:  1 	Train Loss:  0.0007250623100996018 	Val Loss:  0.0003588159129023552
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: Network error resolved after 0:17:13.771521, resuming normal operation.
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: Network error (HTTPError), entering retry loop. See /home/naddeok5/FIM/wandb/run-20210430_061000-jeu30rmv/logs/debug-internal.log for full traceback.
wandb: Network error resolved after 0:41:39.212776, resuming normal operation.
wandb: Network error resolved after 0:12:21.755330, resuming normal operation.
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: Network error resolved after 0:06:28.858441, resuming normal operation.
wandb: Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.
wandb: Network error (HTTPError), entering retry loop. See /home/naddeok5/FIM/wandb/run-20210430_061000-jeu30rmv/logs/debug-internal.log for full traceback.
wandb: Network error resolved after 0:40:48.698505, resuming normal operation.
wandb: Network error resolved after 0:15:14.138690, resuming normal operation.
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 174 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
